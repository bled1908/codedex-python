<!DOCTYPE html>
<!-- saved from url=(0059)https://www.codedex.io/projects/generate-a-blog-with-openai -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script type="text/javascript" async="" src="https://widget.intercom.io/widget/sy5cxa9d"></script><script>fbq("track", "PageView");</script><noscript><img height="1" width="1" style="display:none"
      src="https://www.facebook.com/tr?id=1428382907878082&ev=PageView&noscript=1" /></noscript><script async="" src="./Codédex _ Generate a Blog with OpenAI_files/fbevents.js.download"></script><script>!(function(f, b, e, v, n, t, s) {
        if (f.fbq) return;
        n = f.fbq = function() {
          n.callMethod
            ? n.callMethod.apply(n, arguments)
            : n.queue.push(arguments);
        };
        if (!f._fbq) f._fbq = n;
        n.push = n;
        n.loaded = !0;
        n.version = "2.0";
        n.queue = [];
        t = b.createElement(e);
        t.async = !0;
        t.src = v;
        s = b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t, s);
      })(
        window,
        document,
        "script",
        "https://connect.facebook.net/en_US/fbevents.js"
      );
      fbq("init", "1428382907878082" );</script><meta name="viewport" content="width=device-width"><meta property="og:site_name" content="Codédex"><link rel="icon" href="https://www.codedex.io/images/favicon.png"><title>Codédex | Generate a Blog with OpenAI</title><meta property="og:title" content="Codédex | Generate a Blog with OpenAI"><meta property="og:url" content="https://www.codedex.io/projects/generate-a-blog-with-openai"><meta property="og:image" content="https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/seo.png"><meta property="og:description" content="Learn how to build a blog generator with OpenAI&#39;s GPT-3 and Python and never experience writer&#39;s block again."><meta property="og:type" content="website"><meta property="twitter:image" content="https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/seo.png"><meta name="twitter:title" content="Codédex | Generate a Blog with OpenAI"><meta name="twitter:description" content="Learn how to build a blog generator with OpenAI&#39;s GPT-3 and Python and never experience writer&#39;s block again."><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@codedex_io"><meta name="twitter:creator" content="@codedex_io"><meta name="description" content="Learn how to build a blog generator with OpenAI&#39;s GPT-3 and Python and never experience writer&#39;s block again."><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"Codédex","url":"https://www.codedex.io/"}</script><meta name="next-head-count" content="18"><link data-next-font="" rel="preconnect" href="https://www.codedex.io/" crossorigin="anonymous"><link rel="preload" href="./Codédex _ Generate a Blog with OpenAI_files/47464a9f24cb0721.css" as="style" crossorigin=""><link rel="stylesheet" href="./Codédex _ Generate a Blog with OpenAI_files/47464a9f24cb0721.css" crossorigin="" data-n-g=""><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="./Codédex _ Generate a Blog with OpenAI_files/polyfills-c67a75d1b6f99dc8.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/webpack-f328932c80df97ab.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/framework-fee8a7e75612eda8.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/main-890f3cd7867a0512.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/_app-d8d4122e2094a540.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/252f366e-11fac6c9bb4affe4.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/0c428ae2-ae17e318a8df7196.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/814c6784-37f92ac2e7fa8e11.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/7779ef99-c5560b75938c74db.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9b380ffa-d77ec5665126d8b3.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1349-8fb2c7933fbc3195.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9155-5c7fe9dccc7f3fb7.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/3051-82fc6454c1916a56.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/6961-2415a80c2f922d85.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/[project]-ba85be87e21f5a1b.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/_buildManifest.js.download" defer="" crossorigin=""></script><script src="./Codédex _ Generate a Blog with OpenAI_files/_ssgManifest.js.download" defer="" crossorigin=""></script><style></style><style id="highlight-mengshou-style">
    .highlight-mengshou-wrap {
        background: #ff9;
        cursor: pointer;
    }
    .highlight-mengshou-wrap.active {
        background: #ffb;
    }
</style><style data-styled="active" data-styled-version="5.3.11"></style><script src="./Codédex _ Generate a Blog with OpenAI_files/js" async=""></script><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/c7773329-fa54bb63dd92cb08.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/builds-54598d1833b3f0a9.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/d7eeaac4-345ec750cd25c88a.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/1a48c3c1-23dfc3ea935e511d.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/7f0c75c1-b1f616c95e740897.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/d64684d8-a4c1c1cfc924dd52.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/1e7c12d4-0d18fbb6ccb999fe.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/78e521c3-62c26b4faa24efe6.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/de71a805-7c3eede966dba0ce.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/9755-bff09260aef52f12.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/2238-de67480ff11cdf2f.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/8494-580b351760cfb8cc.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/5818-371a274055635211.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/195-7021e15a6bcaa3ec.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/3623-b6972b8b2444212c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/463-c020b1f6fcf82b36.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/5858-217749e23530c83c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/514-ecfa057b0332c3fa.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/9227-fe997dff71fb3a7a.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/9840-7df7daf4b3c34697.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/community-3e34973f6b297308.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/1bfc9850-71d91d5d4c4301f0.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/1582-8563d1ad7cedcde7.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/5012-a830fa1dad89f297.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/[username]-619ba8ac78469e98.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/1808-be540380790b01c5.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/2042-0fea4c4d00ff07c2.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/python-f34bca7ab3dcab3b.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/7939-cccc9c103cccaf4f.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/index-f608ed53b785bc8e.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/home-634ddd182568da57.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/projects-aa1ce341089ea4d7.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/about-b5a1a2bf867004d8.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/7536-4bba4712c2e8106f.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/9028-3c3b16f34e5a0cf4.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/blog-97568d8bc061a9a9.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/8764-6825f04985bb7b7c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/7066-2f965d9ee63bca07.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/6960-9ac039b89504e9a6.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/967-da4a083246e26285.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/5966-030f98d6e6e29bab.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/pricing-c60a82a8acdf2b8c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/challenges-957f14482b9c008c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/6670-899a6d8dcf09244d.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/2939-7d559b10db873f7e.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/30-nites-of-code-1c52a1088a9477ad.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/courses-992514bb12435da1.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/intermediate-python-745e157bba3bb879.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/numpy-4c748d0e13d214b7.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/sql-ed8646296cb4bda5.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/html-60190679aa30ac93.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/css-217b7281471acfbe.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/javascript-7261cf923525ef6d.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/intermediate-javascript-bffb0e8848f015ea.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/react-f32496530a57d7b0.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/command-line-08a894d029c2d9a5.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/git-github-5362064c420d294e.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/p5js-1aad133b1167a4b3.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/cpp-1803950b1b5f30eb.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/java-346a89f9d8031fef.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/terms-55d86140e1fe697c.js.download"><link as="script" rel="prefetch" href="./Codédex _ Generate a Blog with OpenAI_files/privacy-5838503a47853cdd.js.download"><script src="./Codédex _ Generate a Blog with OpenAI_files/v3"></script></head><body><div id="__next"><link rel="preconnect" href="https://fonts.gstatic.com/"><link rel="preload" href="https://www.codedex.io/fonts/Menlo_Regular.otf" as="font" crossorigin=""><link rel="preload" href="https://www.codedex.io/fonts/Hack-Regular.ttf" as="font" crossorigin=""><link rel="preload" href="https://www.codedex.io/fonts/pixelgrid-squarebolds.woff" as="font" crossorigin=""><link rel="preload" href="https://www.codedex.io/fonts/pixelgrid-squareboldm.woff" as="font" crossorigin=""><link rel="preload" href="https://www.codedex.io/fonts/pixelgrid-squareboldxl.woff" as="font" crossorigin=""><dialog class="sc-bce9ac15-0 hRHLpw nes-dialog is-rounded editor-selector"><button class="close-btn nes-pointer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg></button><div class="parent-container"><div class="selector"><h2>Create a new blank project<span>Select your editor:</span></h2><div class="btn-container"><button type="button" class="language-btn false false"><span><p> <img src="./Codédex _ Generate a Blog with OpenAI_files/python-logo.png" alt="python logo">Python</p></span></button><button type="button" class="language-btn false false"><span><p><img src="./Codédex _ Generate a Blog with OpenAI_files/html-logo.png" alt="html logo">HTML/CSS/JS</p></span></button><button type="button" class="language-btn false false"><span><p> <img src="./Codédex _ Generate a Blog with OpenAI_files/javascript-logo.png" alt="javascript logo">JavaScript</p></span></button><button type="button" class="language-btn false false"><span><p> <img src="./Codédex _ Generate a Blog with OpenAI_files/cpp-logo.svg" alt="cpp logo">C++</p></span></button><button type="button" class="language-btn false false"><span><p> <img src="./Codédex _ Generate a Blog with OpenAI_files/react-icon.webp" alt="react logo">React</p></span></button><button type="button" class="language-btn false false"><span><p> <img src="./Codédex _ Generate a Blog with OpenAI_files/java_logo.png" alt="java logo">Java</p></span></button></div></div><div class="recent-builds"><h2><span>Recent Builds:</span><a href="https://www.codedex.io/builds" style="all: unset;"><span class="see-all nes-pointer">See all</span></a></h2><div class="build-container"><div class="build nes-pointer"><img src="./Codédex _ Generate a Blog with OpenAI_files/python-logo.png" alt="python logo"><p><span class="title">Python workspace</span><span class="date">Dec 28, 2024, 1:45 <span>pm</span></span></p></div><div class="build nes-pointer"><img src="./Codédex _ Generate a Blog with OpenAI_files/python-logo.png" alt="python logo"><p><span class="title">Python workspace</span><span class="date">Dec 28, 2024, 1:45 <span>pm</span></span></p></div><div class="build nes-pointer"><img src="./Codédex _ Generate a Blog with OpenAI_files/python-logo.png" alt="python logo"><p><span class="title">Python workspace</span><span class="date">Dec 27, 2024, 4:37 <span>pm</span></span></p></div></div></div></div></dialog><div id="global-header" class="sc-e205273d-0 fNaMZF"><div class="inner-header-container"><h2 class="sc-57dbb39a-0 ixCmhm nes-pointer"><div class=""><img src="./Codédex _ Generate a Blog with OpenAI_files/coin-cropped.png" width="25px" height="28px" alt="coin logo" class="logo-image animate"></div><a href="https://www.codedex.io/home">Codédex</a><span class="club-notification" data-content="Club">Club</span></h2><div class="sc-f3ebb9b-0 bNRraE"><div class="sc-d07836e7-0 fpSQmu false" style="position: static;"><button class="nes-pointer">Learn<span class="arrow-to-rotate"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M5.83317 6.6665H4.1665V8.33317H5.83317V9.99984H7.49984V11.6665H9.1665V13.3332H10.8332V11.6665H12.4998V9.99984H14.1665V8.33317H15.8332V6.6665H14.1665V8.33317H12.4998V9.99984H10.8332V11.6665H9.1665V9.99984H7.49984V8.33317H5.83317V6.6665Z" fill="#64748B"></path></svg></span></button></div><div class="sc-d07836e7-0 fpSQmu tab-current-path" style="position: relative;"><button class="nes-pointer">Practice<span class="arrow-to-rotate"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M5.83317 6.6665H4.1665V8.33317H5.83317V9.99984H7.49984V11.6665H9.1665V13.3332H10.8332V11.6665H12.4998V9.99984H14.1665V8.33317H15.8332V6.6665H14.1665V8.33317H12.4998V9.99984H10.8332V11.6665H9.1665V9.99984H7.49984V8.33317H5.83317V6.6665Z" fill="#64748B"></path></svg></span></button></div><div class="sc-6bf98e-0 cmTeag"><a href="https://www.codedex.io/builds"><button>Build</button></a></div><div class="sc-7381c9cf-0 dALzWs"><a href="https://www.codedex.io/community"><button>Community </button></a></div><div class="sc-269c0b3d-0 bmUbux"><div class="user-pfp-container"><img src="./Codédex _ Generate a Blog with OpenAI_files/136990707" alt="Login in user profile picture" class="nes-pointer user-profile-image"></div></div></div></div></div><div class="sc-eab8c689-0 hxjOWl"><div class="inner-header-container"><h2 class="sc-57dbb39a-0 ixCmhm nes-pointer"><div class=""><img src="./Codédex _ Generate a Blog with OpenAI_files/coin-cropped.png" width="25px" height="28px" alt="coin logo" class="logo-image"></div><a href="https://www.codedex.io/home">Codédex</a><span class="club-notification" data-content="Club">Club</span></h2><div class="sc-47eaeb7f-0 eVwKYW"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4 6H20V8H4V6ZM4 11.0001H20V13.0001H4V11.0001ZM20 16H4V18H20V16Z" fill="#94A3B8"></path></svg></div></div></div><div style="position: absolute; top: -1rem; font-size: 12px; opacity: 0;"><div><a href="https://www.codedex.io/python">Python</a><a href="https://www.codedex.io/intermediate-python">Intermediate Python</a><a href="https://www.codedex.io/numpy">NumPy</a><a href="https://www.codedex.io/sql">SQL</a><a href="https://www.codedex.io/gen-ai">Gen AI</a></div><div><a href="https://www.codedex.io/html">HTML</a><a href="https://www.codedex.io/css">CSS</a><a href="https://www.codedex.io/javascript">JavaScript</a><a href="https://www.codedex.io/intermediate-javascript">Intermediate JavaScript</a><a href="https://www.codedex.io/react">React</a><a href="https://www.codedex.io/p5js">p5.js</a></div><div><a href="https://www.codedex.io/command-line">Command Line</a><a href="https://www.codedex.io/git-github">Git &amp; GitHub</a></div><div><a href="https://www.codedex.io/cpp">C++</a><a href="https://www.codedex.io/java">Java</a></div></div><div class="outer-app-container-div"><div class="sc-b8ad7ba-0 hLnGnR"><div class="sc-93ebdd97-0 eKFyio"><div class="sc-51084249-0 HeXnd"><ul><li><span class="not-liked"><button style="all: unset;"><img src="./Codédex _ Generate a Blog with OpenAI_files/thumbs-up.png" alt="thumbs up"></button></span><p>48</p></li><li><span class="not-bookmarked"><button style="all: unset;"><img src="./Codédex _ Generate a Blog with OpenAI_files/bookmark.png" alt="bookmark"></button></span><p>80</p></li><li><span class="not-shared"><button style="all: unset;"><img src="./Codédex _ Generate a Blog with OpenAI_files/share-06.png" alt="share"></button><div class="share-to"><p>Share to: </p><i><a href="https://twitter.com/intent/tweet?url=https://www.codedex.io/projects/generate-a-blog-with-openai&amp;text=Generate%20a%20Blog%20with%20OpenAI" target="_blank" rel="noreferrer"><img src="./Codédex _ Generate a Blog with OpenAI_files/twitter.png" alt="twitter link"></a></i><i><a href="https://www.reddit.com/submit?url=https://www.codedex.io/projects/generate-a-blog-with-openai&amp;title=Generate%20a%20Blog%20with%20OpenAI" target="_blank" rel="noreferrer"><img src="./Codédex _ Generate a Blog with OpenAI_files/reddit.png" alt="reddit link"></a></i><i><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://www.codedex.io/projects/generate-a-blog-with-openai&amp;title=Generate%20a%20Blog%20with%20OpenAI" target="_blank" rel="noreferrer"><img src="./Codédex _ Generate a Blog with OpenAI_files/linkedin.png" alt="linkedin link"></a></i><i><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.codedex.io/projects/generate-a-blog-with-openai&amp;t=Generate%20a%20Blog%20with%20OpenAI" target="_blank" rel="noreferrer"><img src="./Codédex _ Generate a Blog with OpenAI_files/facebook.png" alt="twitter link"></a></i></div><div class="hover-active"></div></span><p>4</p></li></ul><div class="mobile-view"><li><span class="not-liked"><button style="all: unset;"><img src="./Codédex _ Generate a Blog with OpenAI_files/thumbs-up.png" alt="thumbs up"></button></span><p>48</p></li><li><span class="not-bookmarked"><button style="all: unset;"><img src="./Codédex _ Generate a Blog with OpenAI_files/bookmark.png" alt="bookmark"></button></span><p>80</p></li></div></div><div class="mdx-container"><section class="sc-2961456b-0 cKOVAz dark"><div class="sc-bce5c1dd-0 frdCZV yellow"><div class="image-container for-sidebar"><img src="./Codédex _ Generate a Blog with OpenAI_files/header.png" alt="Title Image"></div></div>
<h1 id="generate-a-blog-with-openai"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#generate-a-blog-with-openai"><span></span></a>Generate a Blog with OpenAI</h1>
<div class="sc-7cd098a4-1 cIhzph"><div class="author"><img class="sc-7cd098a4-0 GTfAj author-avatar dark" alt="" src="./Codédex _ Generate a Blog with OpenAI_files/asiqur_rahman.png"> Asiqur Rahman</div></div>
<div class="sc-bce5c1dd-0 frdCZV yellow"><div class="image-container undefined"><img src="./Codédex _ Generate a Blog with OpenAI_files/header.png" alt="Title Image"></div></div>
<p><strong>Prerequisites:</strong> Python fundamentals<br>
<strong>Versions:</strong> Python 3.10, python-dotenv 0.21.0, openai 1.0.0<br>
<strong>Read Time:</strong> 60 minutes</p>
<h2 id="introduction"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#introduction"><span>#</span></a> Introduction</h2>
<p><a href="https://en.wikipedia.org/wiki/Artificial_intelligence" target="_blank" rel="nofollow noreferrer noopener">Artificial Intelligence (AI)</a> is becoming the next big technology to harness. From smart fridges to self-driving cars, AI is implemented in almost everything you can think of. So let's get ahead of the pack and learn how we can leverage the power of AI with Python and OpenAI.</p>
<p>In this tutorial, we'll learn how to create a blog generator with <a href="https://openai.com/api/" target="_blank" rel="nofollow noreferrer noopener">GPT-3</a>, an AI model provided by <a href="https://www.openai.com/" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a>. The generator will read a topic to talk about as the input, and GPT-3 will return us a paragraph about that topic as the output.</p>
<p>So AI will be "writing" stuff for us. Say goodbye to writer's block!</p>
<p>But wait, hold on! Artificial intelligence?! AI models?! This must be complicated to code. 😵</p>
<img src="./Codédex _ Generate a Blog with OpenAI_files/calculation-math.gif" alt="meme" class="sc-7a547a4a-0 dAWnTE">
<p>Nope, it's easier than you think. It takes around 25 lines of Python code!</p>
<p>The final result will look something like this:</p>
<img src="./Codédex _ Generate a Blog with OpenAI_files/generator-demo.gif" alt="generator demo" class="sc-7a547a4a-0 dAWnTE">
<p><em>Who knows, maybe this entire project was written by the generator we're about to create. 👀</em></p>
<h2 id="what-is-gpt-3"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#what-is-gpt-3"><span>#</span></a> What is GPT-3?</h2>
<p><a href="https://en.wikipedia.org/wiki/GPT-3" target="_blank" rel="nofollow noreferrer noopener">GPT-3</a> is an AI model released by OpenAI in 2020. An AI model is a program trained on a bunch of data to perform a specific task. In this case, GPT-3 was trained to speak like a human and predict what comes next given the context of a sentence, with its training dataset being 45 terabytes of text (!) from the internet.</p>
<blockquote>
<p>For reference, if you had to keep writing until your paper hits 45 terabytes in size, you would have to write <a href="https://www.techtarget.com/searchstorage/definition/How-many-bytes-for" target="_blank" rel="nofollow noreferrer noopener">22,500,000,000</a> pages worth of plain text.</p>
</blockquote>
<p>Since GPT-3 was trained on internet data, it knows what the internet knows (not everything of course). This means that if we were to give GPT-3 a sentence, it would be able to predict what comes next in that sentence with high accuracy, based on all the text that was used to train it.</p>
<p>Now we know what we'll be working with, let's build the program!</p>
<h2 id="setting-up"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#setting-up"><span>#</span></a> Setting Up</h2>
<h3 id="openai-account"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#openai-account"><span>##</span></a> OpenAI Account</h3>
<p>Before we do anything, we need an <a href="https://openai.com/api" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a> account. We'll need this to access an API key for using GPT-3. Note that OpenAI no longer offers free credits, so you'll need to purchase at least 5 dollars worth of credits to start using the API.</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/API" target="_blank" rel="nofollow noreferrer noopener">API (Application Programming Interface)</a> is a way for two computers to communicate with each other. Think of it like two friends texting back and forth. An API key is a code we receive to access the API. Think of it like an important password, so don’t share it with others!</p>
</blockquote>
<p>Go to <a href="http://www.openai.com/" target="_blank" rel="nofollow noreferrer noopener">www.openai.com</a> and sign up for an OpenAI account.</p>
<p>After you've created an account, click on your profile picture on the top right, then click "View API keys" to access your API key. You should see <a href="https://beta.openai.com/account/api-keys" target="_blank" rel="nofollow noreferrer noopener">this page</a> and it should look like:</p>
<img src="./Codédex _ Generate a Blog with OpenAI_files/api-key.png" alt="API Key" class="sc-7a547a4a-0 dAWnTE">
<p>Now that we know where the API key is located, let's keep it in mind for later.</p>
<h3 id="python-setup"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#python-setup"><span>##</span></a> Python Setup</h3>
<p>For this project, we'll need <a href="https://www.python.org/downloads/" target="_blank" rel="nofollow noreferrer noopener">Python 3</a> and <a href="https://pip.pypa.io/en/stable/" target="_blank" rel="nofollow noreferrer noopener">pip</a> (package installer) installed.</p>
<p>Assuming that we have those two installed, let's open up the code editor of our choice (we recommend <a href="https://code.visualstudio.com/" target="_blank" rel="nofollow noreferrer noopener">VS Code</a>) and create a new file called <strong>blog_generator.py</strong>.</p>
<p><strong>Note</strong>: You can name this file anything except for <strong>openai.py</strong>, since the name will clash with a package we'll be installing.</p>
<h2 id="beginning-the-project"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#beginning-the-project"><span>#</span></a> Beginning the Project</h2>
<p>At the core of this project, all we'll be doing is sending data with instructions to a server owned by OpenAI, then receiving a response back from that server and displaying it.</p>
<h3 id="install-openai"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#install-openai"><span>##</span></a> Install openai</h3>
<p>We'll be interacting with GPT-3 model using a python package called <code>openai</code>. This package consists of methods that can connect to the internet and grant us access to the GPT-3 model hosted by OpenAI, the company.</p>
<p>To install <code>openai</code>, all we have to do is run the following command in our terminal:</p>
<pre id="code-block-0"><code class="hljs language-sh">pip install openai
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>We can now use this package by importing it into our <strong>blog_generator.py</strong> file like so:</p>
<pre id="code-block-1"><code class="hljs language-py"><span class="hljs-keyword">import</span> openai
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<h3 id="authorize-api-key"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#authorize-api-key"><span>##</span></a> Authorize API Key</h3>
<p>Before we can work with GPT-3 we need to set our API key in the <code>openai</code> module. Remember, the API key is what gives us access to GPT-3; it authorizes us and says we're allowed to use this API.</p>
<p>We can set our API key by extending a method in the <code>openai</code> module called <code>api_key</code>:</p>
<pre id="code-block-2"><code class="hljs language-py">openai.api_key = <span class="hljs-string">'Your_API_Key'</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>The method will take in the API key as a string. Remember, your API key is located in your <a href="https://beta.openai.com/account/api-keys" target="_blank" rel="nofollow noreferrer noopener">OpenAI account</a>.</p>
<p>So far, the code should look like this:</p>
<pre id="code-block-3"><code class="hljs language-py"><span class="hljs-keyword">import</span> openai

openai.api_key = <span class="hljs-string">'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk'</span> <span class="hljs-comment"># Fill in your own key</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<h2 id="the-core-function"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#the-core-function"><span>#</span></a> The Core Function</h2>
<p>Now that we have access to GPT-3, we can get to the meat of the application, which is creating a function that takes in a prompt as user input and returns a paragraph about that prompt.</p>
<p>That function will look like this:</p>
<pre id="code-block-4"><code class="hljs language-py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_blog</span>(<span class="hljs-params">paragraph_topic</span>):
  response = openai.completions.create(
    model = <span class="hljs-string">'gpt-3.5-turbo-instruct'</span>,
    prompt = <span class="hljs-string">'Write a paragraph about the following topic. '</span> + paragraph_topic,
    max_tokens = <span class="hljs-number">400</span>,
    temperature = <span class="hljs-number">0.3</span>
  )

  retrieve_blog = response.choices[<span class="hljs-number">0</span>].text

  <span class="hljs-keyword">return</span> retrieve_blog
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>Let's break down this function and see what's going on here.</p>
<p>First, we defined a function called <code>generate_blog()</code>. There's a single parameter called <code>paragraph_topic</code>, which will be the topic used to generate the paragraph:</p>
<pre id="code-block-5"><code class="hljs language-py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_blog</span>(<span class="hljs-params">paragraph_topic</span>):
  <span class="hljs-comment"># The code inside</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>And let's go inside the function. Here's the first part:</p>
<pre id="code-block-6"><code class="hljs language-py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_blog</span>(<span class="hljs-params">paragraph_topic</span>):
  response = openai.completions.create(
    model = <span class="hljs-string">'gpt-3.5-turbo-instruct'</span>,
    prompt = <span class="hljs-string">'Write a paragraph about the following topic. '</span> + paragraph_topic,
    max_tokens = <span class="hljs-number">400</span>,
    temperature = <span class="hljs-number">0.3</span>
  )
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>This is the bulk of our function and where we use GPT-3. We created a variable called <code>response</code> to store the response generated by the output of the <code>completions.create()</code> method call in our <code>openai</code> module.</p>
<p>GPT-3 has different endpoints for specific purposes, but for our goal, we'll use the <a href="https://beta.openai.com/docs/api-reference/completions" target="_blank" rel="nofollow noreferrer noopener">completion</a> endpoint. The completion endpoint will generate text depending on the provided prompt. You can read about the different endpoints in the <a href="https://beta.openai.com/docs/introduction" target="_blank" rel="nofollow noreferrer noopener">documentation</a>.</p>
<p>Now that we have access to the completion endpoint, we need to specify a few things, The first one being:</p>
<p><code>model</code>: The model parameter will take in the model we want to use. OpenAI offers several models with different capabilities. For this tutorial, we are using <code>gpt-3.5-turbo-instruct</code> to provide clear and reliable examples.</p>
<p>Syntax and capabilities varies between models. You can read more about the available models in the <a href="https://platform.openai.com/docs/models" target="_blank" rel="nofollow noreferrer noopener">documentation</a>.</p>
<pre id="code-block-7"><code class="hljs language-py">prompt = <span class="hljs-string">'Write a paragraph about the following topic. '</span> + paragraph_topic,
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p><code>prompt</code>: This is where we design the main instructions for GPT-3. This parameter will take in our <code>paragraph_topic</code> argument, but before that, we can tell GPT-3 what to do with that argument. Currently, we are instructing GPT-3 to <code>Write a paragraph about the following topic</code>. GPT-3 will try its best to follow this instruction and return us a paragraph.</p>
<p>GPT-3 is very flexible; if the initial string is changed to <code>Write a blog outline about the following topic</code>, it will give us an outline instead of a normal paragraph. You can later play around with this by telling the model exactly what it should generate and seeing what interesting responses you get.</p>
<pre id="code-block-8"><code class="hljs language-py">max_tokens = <span class="hljs-number">400</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p><code>tokens</code>: The token number decides how long the response is going to be. A larger token number will produce a longer response. By setting a specific number, we're saying that the response can't go past this token size. The way tokens are counted towards a response is a bit complex, but you can read this <a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them" target="_blank" rel="nofollow noreferrer noopener">article</a> by OpenAI that explains how token size is calculated.</p>
<p>Roughly 75 words is about 100 tokens. A paragraph has 300 words on average. So, 400 tokens is about the length of a normal paragraph. The model <code>gpt-3.5-turbo-instruct</code> has a token limit of 4,096.</p>
<pre id="code-block-9"><code class="hljs language-py">temperature = <span class="hljs-number">0.3</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p><code>temperature</code>: Temperature determines the randomness of a response. A higher temperature will produce a more creative response, while a lower temperature will produce a more well-defined response.</p>
<ul>
<li><code>0</code>: The same response every time.</li>
<li><code>1</code>: A different response every time, even if it's the same prompt.</li>
</ul>
<p>There are plenty of other fields that we can specify to fine-tune the model even more, which you can read in the <a href="https://beta.openai.com/docs/api-reference/completions/create" target="_blank" rel="nofollow noreferrer noopener">documentation</a>, but for now, these are the four fields we need to concern ourselves with.</p>
<p>Now that we have our model setup, we can run our function, and the following things will happen:</p>
<ol>
<li>First, the <code>openai</code> module will take our API key, along with the fields we specified in the <code>response</code> variable, and make a request to the completion endpoint.</li>
<li>OpenAI will then verify that we're allowed to use GPT-3 by verifying our API key.</li>
<li>After verification, GPT-3 will use the specified fields to produce a response.</li>
<li>The produced response will be returned back in the form of an object and stored in the <code>response</code> variable.</li>
</ol>
<p>That returned object will look like this:</p>
<pre id="code-block-10"><code class="hljs language-swift">{
  <span class="hljs-string">"choices"</span>: [
    {
      <span class="hljs-string">"finish_reason"</span>: <span class="hljs-string">"stop"</span>,
      <span class="hljs-string">"index"</span>: <span class="hljs-number">0</span>,
      <span class="hljs-string">"logprobs"</span>: null,
      <span class="hljs-string">"text"</span>: <span class="hljs-string">"<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>Python is a programming language with many features, such as an intuitive syntax and powerful data structures. It was created in the late 1980s by Guido van Rossum, with the goal of providing a simple yet powerful scripting language. Python has since become one of the most popular programming languages, with a wide range of applications in fields such as web development, scientific computing, and artificial intelligence."</span>
    }
  ],
  <span class="hljs-string">"created"</span>: <span class="hljs-number">1664302504</span>,
  <span class="hljs-string">"id"</span>: <span class="hljs-string">"cmpl-5v9OiMOjRyoyypRQWAdpyAtjtgVev"</span>,
  <span class="hljs-string">"model"</span>: <span class="hljs-string">"gpt-3.5-turbo-instruct"</span>,
  <span class="hljs-string">"object"</span>: <span class="hljs-string">"text_completion"</span>,
  <span class="hljs-string">"usage"</span>: {
    <span class="hljs-string">"completion_tokens"</span>: <span class="hljs-number">80</span>,
    <span class="hljs-string">"prompt_tokens"</span>: <span class="hljs-number">19</span>,
    <span class="hljs-string">"total_tokens"</span>: <span class="hljs-number">99</span>
  }
}
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>We’re provided with tons of information about the response, but the only thing we care about is the <code>text</code> field containing generated text.</p>
<p>We can access the value in the <code>text</code> field like so:</p>
<pre id="code-block-11"><code class="hljs language-ini"><span class="hljs-attr">retrieve_blog</span> = response.choices[<span class="hljs-number">0</span>].text
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>Finally, we return the <code>retrieve_blog</code> variable which holds the paragraph we just dug out of the dictionary.</p>
<pre id="code-block-12"><code class="hljs language-kotlin"><span class="hljs-keyword">return</span> retrieve_blog
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>Whoah! Let's take a moment and breathe. That was a lot we just covered. Let's give ourselves a pat on the back as we're 90% done with the application.</p>
<p>We can test to see if our code works so far by printing out the <code>generate_blog()</code> function we just created, giving it a topic to write about, and seeing the response we get.</p>
<pre id="code-block-13"><code class="hljs language-py"><span class="hljs-built_in">print</span>(generate_blog(<span class="hljs-string">'Why NYC is better than your city.'</span>))
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>Here's the complete code so far:</p>
<pre id="code-block-14"><code class="hljs language-py"><span class="hljs-keyword">import</span> openai

openai.api_key = <span class="hljs-string">'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk'</span> <span class="hljs-comment"># Fill in your own key</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_blog</span>(<span class="hljs-params">paragraph_topic</span>):
  response = openai.completions.create(
    model = <span class="hljs-string">'gpt-3.5-turbo-instruct'</span>,
    prompt = <span class="hljs-string">'Write a paragraph about the following topic. '</span> + paragraph_topic,
    max_tokens = <span class="hljs-number">400</span>,
    temperature = <span class="hljs-number">0.3</span>
  )

  retrieve_blog = response.choices[<span class="hljs-number">0</span>].text

  <span class="hljs-keyword">return</span> retrieve_blog

<span class="hljs-built_in">print</span>(generate_blog(<span class="hljs-string">'Why NYC is better than your city.'</span>))
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>And boom, after 2-3 seconds, it should spit out a paragraph like this:</p>
<p><img src="./Codédex _ Generate a Blog with OpenAI_files/output-nyc.png" alt="Output: NYC"></p>
<p>Try running the code a couple more times; the output should be different every time! 🤯</p>
<h2 id="multiple-paragraphs"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#multiple-paragraphs"><span>#</span></a> Multiple Paragraphs</h2>
<p>Right now, if we run our code, we'll only be able to generate one paragraph worth of text. Remember, we're trying to create a blog generator, and a blog has multiple sections, with each paragraph having a different topic.</p>
<p>Let's add some additional code to generate as many paragraphs as we want, with each paragraph discussing a different topic:</p>
<pre id="code-block-15"><code class="hljs language-py">keep_writing = <span class="hljs-literal">True</span>

<span class="hljs-keyword">while</span> keep_writing:
  answer = <span class="hljs-built_in">input</span>(<span class="hljs-string">'Write a paragraph? Y for yes, anything else for no. '</span>)
  <span class="hljs-keyword">if</span> (answer == <span class="hljs-string">'Y'</span>):
    paragraph_topic = <span class="hljs-built_in">input</span>(<span class="hljs-string">'What should this paragraph talk about? '</span>)
    <span class="hljs-built_in">print</span>(generate_blog(paragraph_topic))
  <span class="hljs-keyword">else</span>:
    keep_writing = <span class="hljs-literal">False</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>First, we defined a variable called <code>keep_writing</code>, to use as a boolean value for the following <code>while</code> loop.</p>
<p>In the <code>while</code> loop, we created an <code>answer</code> variable that will take in an input from the user using the built-in <code>input()</code> function.</p>
<p>We then created an <code>if</code> statement that will either continue the loop or stop the loop.</p>
<ul>
<li>If the input from the user is <code>Y</code>, then we will ask the user what topic they want to generate text about, storing that value in a variable called <code>paragraph_topic</code>. Then we will execute and print the <code>generate_blog()</code> function using the <code>parapgraph_topic</code> variable as its argument.</li>
<li>Else, we will stop the loop by assigning the <code>keep_writing</code> variable to <code>False</code>.</li>
</ul>
<p>With that complete, we can now write as many paragraphs as we want by running the program once!</p>
<h3 id="rate-limit"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#rate-limit"><span>##</span></a> Rate Limit</h3>
<p>Since we're using a <code>while</code> loop, we have the potential to be rate limited.</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Rate_limiting" target="_blank" rel="nofollow noreferrer noopener">Rate limit</a> is the number of API calls an app or user can make within a given time period.</p>
</blockquote>
<p>This is normally done to protect the API from abuse or <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack" target="_blank" rel="nofollow noreferrer noopener">DoS</a> attacks.</p>
<p>For GPT-3, the rate limit is 20 requests per minute. As long as we don't run the function that fast, we'll be fine. But in a rare case that it does occur, GPT-3 will stop producing responses and make us wait a minute to produce another response.</p>
<h3 id="credit-limit"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#credit-limit"><span>##</span></a> Credit Limit</h3>
<p>By this point, if you have been playing with the API nonstop, there's a chance that you might have exceeded your purchased credit limit. The following error is thrown when that happens:</p>
<pre id="code-block-16"><code class="hljs language-bash">openai.error.RateLimitError:  
You exceeded your current quota, please check your plan and billing details.
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>If that's the case, go to OpenAI's <a href="https://platform.openai.com/settings/organization/billing/overview" target="_blank" rel="nofollow noreferrer noopener">Billing overview</a> page and purchase additional credits.</p>
<p>Let's take another breather. We're almost done!</p>
<h2 id="securing-our-app"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#securing-our-app"><span>#</span></a> Securing Our App</h2>
<p>Let's think about this for a minute. We created this amazing application and want to share it with the world, right? Well, when we deploy it to the web or share it with our friends, they'll be able to see every piece of code in the program. That's where the issue lies!</p>
<p>At the beginning of this article, we created an account with OpenAI and were assigned an API key. Remember, this API key is what gives us access to GPT-3. Since GPT-3 is a paid service, the API key is also used to track usage and charge us accordingly. So what happens when someone knows our API key? They'll be able to use the service with our key, and we'll be the one charged, potentially thousands of dollars!</p>
<p>In order to protect ourselves, we need to hide the API key in our code but still be able to use it. Let's see how we can do that.</p>
<h3 id="install-python-dotenv"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#install-python-dotenv"><span>##</span></a> Install <code>python-dotenv</code></h3>
<p><a href="https://pypi.org/project/python-dotenv" target="_blank" rel="nofollow noreferrer noopener"><code>python-dotenv</code></a> is a package that allows us to create and use environment variables without having to set them in the operating system manually.</p>
<blockquote>
<p>Environment variables are variables whose values are set outside the program, typically in the operating system.</p>
</blockquote>
<p>We can install <code>python-dotenv</code> by running the following command in the terminal:</p>
<pre id="code-block-17"><code class="hljs language-sh">pip install python-dotenv
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<h3 id="env-file"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#env-file"><span>##</span></a> .env File</h3>
<p>Then in our project's root directory, create a file called <strong>.env</strong>. This file will hold our environment variable.</p>
<p>Open up the <strong>.env</strong> file and create a variable like so:</p>
<pre id="code-block-18"><code class="hljs language-ini"><span class="hljs-attr">API_KEY</span>=&lt;Your_API_Key&gt;
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>The variable will take in our API key without any quotation marks or spaces. Remember to name this variable as <code>API_KEY</code> only.</p>
<h3 id="python-file"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#python-file"><span>##</span></a> Python File</h3>
<p>Now that we have our environment variable set, let's open up the <strong>blog_generator.py</strong> file, and paste this code under <code>import openai</code>.</p>
<pre id="code-block-19"><code class="hljs language-py"><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> dotenv_values

config = dotenv_values(<span class="hljs-string">".env"</span>)
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>First, we've imported a method called <code>dotenv_values</code> from the module.</p>
<p>The <code>dotenv_values()</code> will take in the path to the <strong>.env</strong> file and return us a dictionary with all the variables in the <strong>.env</strong> file. We then created a <code>config</code> variable to hold that dictionary.</p>
<p>Now, all we have to do is replace the exposed API key with the environment variable in the <code>config</code> dictionary like so:</p>
<pre id="code-block-20"><code class="hljs language-py">openai.api_key = config[<span class="hljs-string">'API_KEY'</span>]
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p>That's it! Our API key is now safe and hidden from the main code.</p>
<p><strong>Note</strong>: If you want to push your code to <a href="https://www.github.com/" target="_blank" rel="nofollow noreferrer noopener">GitHub</a>, you don't want to push the <strong>.env</strong> file as well. In the root directory of your project, create a file called <strong>.gitignore</strong>, and in the Git ignore file, type in <code>.env</code>. This will prevent the file from being tracked by Git and ultimately pushed to GitHub.</p>
<p>With all that set and done, we’re finished! The code should now look like this!</p>
<p><strong>blog_generator.py</strong> file:</p>
<pre id="code-block-21"><code class="hljs language-py"><span class="hljs-comment"># Generate a Blog with OpenAI 📝</span>

<span class="hljs-keyword">import</span> openai
<span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> dotenv_values

config = dotenv_values(<span class="hljs-string">'.env'</span>)

openai.api_key = config[<span class="hljs-string">'API_KEY'</span>]

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_blog</span>(<span class="hljs-params">paragraph_topic</span>):
  response = openai.completions.create(
    model = <span class="hljs-string">'gpt-3.5-turbo-instruct'</span>,
    prompt = <span class="hljs-string">'Write a paragraph about the following topic. '</span> + paragraph_topic,
    max_tokens = <span class="hljs-number">400</span>,
    temperature = <span class="hljs-number">0.3</span>
  )
  retrieve_blog = response.choices[<span class="hljs-number">0</span>].text
  <span class="hljs-keyword">return</span> retrieve_blog

keep_writing = <span class="hljs-literal">True</span>

<span class="hljs-keyword">while</span> keep_writing:
  answer = <span class="hljs-built_in">input</span>(<span class="hljs-string">'Write a paragraph? Y for yes, anything else for no. '</span>)
  <span class="hljs-keyword">if</span> (answer == <span class="hljs-string">'Y'</span>):
    paragraph_topic = <span class="hljs-built_in">input</span>(<span class="hljs-string">'What should this paragraph talk about? '</span>)
    <span class="hljs-built_in">print</span>(generate_blog(paragraph_topic))
  <span class="hljs-keyword">else</span>:
    keep_writing = <span class="hljs-literal">False</span>
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<p><strong>.env</strong> file:</p>
<pre id="code-block-22"><code class="hljs language-bash">API_KEY=sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk
</code><div class="copy-button nes-pointer"><button class="sc-9fa15ce7-0 bGRTM nes-pointer " style="position: absolute; right: 0px; top: 0px;"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 15 15" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg" style="transform: rotate(270deg);"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor"></path></svg></button></div></pre>
<h2 id="finish-line"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#finish-line"><span>#</span></a> Finish Line</h2>
<p>Congrats, you just created a blog generator with OpenAI and Python! Throughout the project, we learned how to use GPT-3 to generate a paragraph, use a <code>while</code> loop to create multiple paragraphs, and secure our app with a <strong>.env</strong> file. 🙌</p>
<p>AI is expanding rapidly, and the first few to utilize it properly through services like GPT-3 will become the inovators in the field. Hope this project helps you understand it a bit more.</p>
<p>And lastly, we would love to see what you build with this tutorial! Tag <a href="https://www.codedex.io/projects/@codedex_io">@codedex_io</a> and <a href="https://twitter.com/openai" target="_blank" rel="nofollow noreferrer noopener">@openai</a> on Twitter if you make something cool!</p>
<h3 id="more-resources"><a aria-hidden="true" tabindex="-1" href="https://www.codedex.io/projects/generate-a-blog-with-openai#more-resources"><span>##</span></a> More Resources</h3>
<ul>
<li><a href="https://github.com/codedex-io/projects/blob/main/projects/generate-a-blog-with-openai/blog_generator.py" target="_blank" rel="nofollow noreferrer noopener">Solution on GitHub</a></li>
<li><a href="https://openai.com/" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a></li>
<li><a href="https://pypi.org/project/python-dotenv" target="_blank" rel="nofollow noreferrer noopener">python-dotenv</a></li>
</ul><div class="sc-d8a1bd2-0 gMFeyN btn-container" style="margin-top: 3rem; flex-wrap: wrap;"><a href="https://www.codedex.io/projects"><button class="sc-121fa9db-0 hosgQt undefined nes-pointer "><span class="before"></span><span class="btn-content">Back</span><span class="after"></span></button></a><button class="sc-121fa9db-0 eQGLpc is-primary nes-pointer "><span class="before"></span><span class="btn-content">Complete</span><span class="after"></span></button><a target="_blank" href="https://codedex.typeform.com/to/MJT7aWfz"><button class="sc-121fa9db-0 hosgQt undefined nes-pointer "><span class="before"></span><span class="btn-content">Give Feedback</span><span class="after"></span></button></a><canvas style="position: fixed; pointer-events: none; width: 100%; height: 100%; top: 0px; left: 0px; z-index: 10;"></canvas></div><div><p class="need-help nes-pointer" style="user-select: none; position: relative;">Need Help?</p><div class="sc-3a576a8c-0 kFLmTr hidden nes-container is-rounded is-dark"><p>Did you know that you can join our <a href="https://www.codedex.io/community">Community</a> to get live help from our Code Mentors?</p><p class="or">OR</p><div><img src="./Codédex _ Generate a Blog with OpenAI_files/info-logo.png" alt="infographics" style="width: 18px; height: 18px; display: inline-block;"> <a target="_blank" rel="noreferrer" href="https://codedex.typeform.com/to/jOxqq3Sf">Report a bug</a></div></div></div></section></div><div class="sc-1941fddd-0 htKEqh"><div class="main-container"><div class="author-container"><div class="author-banner"><div class="coin"><img src="./Codédex _ Generate a Blog with OpenAI_files/coin-cropped.png" alt="codedex coin"></div></div><div class="author-profile"><div class="author-name-image"><div class="profile-pic-container"><img src="./Codédex _ Generate a Blog with OpenAI_files/profile.png" alt="author image" class="profile-pic"></div><div class="name"><div><h4>Asiqur Rahman</h4><p>Joined 10-26-2022</p></div></div></div><div class="author-socials"><button type="button">View Profile</button><div class="social"><a target="_blank" rel="noreferrer" href="https://twitter.com/Asiqur14"><i class="nes-icon twitter is-medium"></i></a><a target="_blank" rel="noreferrer" href="https://github.com/asiqurrahman"><i class="nes-icon github is-medium"></i></a><a target="_blank" rel="noreferrer" href="https://linkedin.com/in/asiqurrahman13"><i class="nes-icon linkedin is-medium"></i></a></div></div><div class="author-description"><p>I code stuff for the platform you're currently on. 
Spotify addict. 
I like games.
I like food.
</p></div><ul class="author-roles"><li><i><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" color="#008feb" height="17" width="17" xmlns="http://www.w3.org/2000/svg" style="color: rgb(0, 143, 235);"><path d="M515.664-.368C305.76-.368 128 178.4 128 390.176c0 221.76 206.032 448.544 344.624 607.936.528.64 22.929 25.52 50.528 25.52h2.449c27.6 0 49.84-24.88 50.399-25.52 130.064-149.52 320-396.048 320-607.936C896 178.4 757.344-.368 515.664-.368zm12.832 955.552c-1.12 1.12-2.753 2.369-4.193 3.409-1.472-1.008-3.072-2.288-4.255-3.408l-16.737-19.248C371.92 785.2 192 578.785 192 390.176c0-177.008 148.224-326.56 323.664-326.56 218.528 0 316.336 164 316.336 326.56 0 143.184-102.128 333.296-303.504 565.008zm-15.377-761.776c-106.032 0-192 85.968-192 192s85.968 192 192 192 192-85.968 192-192-85.968-192-192-192zm0 320c-70.576 0-129.473-58.816-129.473-129.408 0-70.576 57.424-128 128-128 70.624 0 128 57.424 128 128 .032 70.592-55.903 129.408-126.527 129.408z"></path></svg></i><span>Brooklyn, NY</span></li><li><i><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="#008feb" height="17" width="17" xmlns="http://www.w3.org/2000/svg" style="color: rgb(0, 143, 235);"><path d="M6.5 1A1.5 1.5 0 0 0 5 2.5V3H1.5A1.5 1.5 0 0 0 0 4.5v8A1.5 1.5 0 0 0 1.5 14h13a1.5 1.5 0 0 0 1.5-1.5v-8A1.5 1.5 0 0 0 14.5 3H11v-.5A1.5 1.5 0 0 0 9.5 1h-3zm0 1h3a.5.5 0 0 1 .5.5V3H6v-.5a.5.5 0 0 1 .5-.5zm1.886 6.914L15 7.151V12.5a.5.5 0 0 1-.5.5h-13a.5.5 0 0 1-.5-.5V7.15l6.614 1.764a1.5 1.5 0 0 0 .772 0zM1.5 4h13a.5.5 0 0 1 .5.5v1.616L8.129 7.948a.5.5 0 0 1-.258 0L1 6.116V4.5a.5.5 0 0 1 .5-.5z"></path></svg></i><span>Software Engineer @ Codédex</span></li></ul></div></div><h3 class="recommanded-course">RECOMMENDED COURSE</h3><div class="take-course"><h3 class="python">The Legend of Python</h3></div></div></div></div></div></div><footer class="sc-a735c9d-0 kBNKSt" style="margin-top: 3rem;"><div class="outer-app-container-div"><div class="sc-b8ad7ba-0 hLnGnR"><div class="inner-footer-container"><div class="sc-36ce7f99-0 ddQUjs"><div class="logo-container"><div class="logo"><audio src="/audio/codedex_pronunciation.mp3" class="codedex-pronouncing-sound"></audio><img src="./Codédex _ Generate a Blog with OpenAI_files/coin-cropped.png" alt="twitter logo"><span>Codédex</span><svg class="nes-pointer" xmlns="http://www.w3.org/2000/svg" width="25" height="24" viewBox="0 0 25 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.56 2H9.56V4H7.56V6H5.56V8H3.56H1.56V10V14V16H3.56H5.56V18H7.56V20H9.56V22H11.56V2ZM7.56 18V16H5.56V14H3.56V10H5.56V8H7.56V6H9.56V18H7.56ZM13.56 10H15.56V14H13.56V10ZM21.56 4H19.56V2H13.56V4H19.56V6H21.56V18H19.56V20H13.56V22H19.56V20H21.56V18H23.56V6H21.56V4ZM19.56 8H17.56V6H13.56V8H17.56V16H13.56V18H17.56V16H19.56V8Z" fill="#94A3B8"></path></svg></div><div class="love-text"><p>Made with</p><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M7.5 3.33301V4.99967H9.16667V6.66634H10.8333V4.99967H12.5V3.33301H15.8333V4.99967H17.5V9.99967H15.8333V11.6663H14.1667V13.333H12.5V14.9997H10.8333V16.6663H9.16667V14.9997H7.5V13.333H5.83333V11.6663H4.16667V9.99967H2.5V4.99967H4.16667V3.33301H7.5Z" fill="#F43F5E"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M7.50004 1.66699H4.16671V3.33366H2.50004V5.00033H0.833374V10.0003H2.50004V11.667H4.16671V13.3337H5.83337V15.0003H7.50004V16.667H9.16671V18.3337H10.8334V16.667H12.5V15.0003H14.1667V13.3337H15.8334V11.667H17.5V10.0003H19.1667V5.00033H17.5V3.33366H15.8334V1.66699H12.5V3.33366H10.8334V5.00033H9.16671V3.33366H7.50004V1.66699ZM7.50004 3.33366V5.00033H9.16671V6.66699H10.8334V5.00033H12.5V3.33366H15.8334V5.00033H17.5V10.0003H15.8334V11.667H14.1667V13.3337H12.5V15.0003H10.8334V16.667H9.16671V15.0003H7.50004V13.3337H5.83337V11.667H4.16671V10.0003H2.50004V5.00033H4.16671V3.33366H7.50004Z" fill="#020617"></path><rect x="14.1666" y="5" width="1.66667" height="1.66667" fill="white"></rect><rect x="14.1666" y="6.66699" width="1.66667" height="1.66667" fill="white"></rect><rect x="12.5" y="5" width="1.66667" height="1.66667" fill="white"></rect></svg><p>in Brooklyn, NY</p></div></div></div><div class="sc-1b39121b-0 hRmOuq"><div class="sc-9c9aac60-0 kHqbpb"><div class="row-title"><p>COMPANY</p></div><div class="links"><a target="_blank" href="https://www.codedex.io/about"><span class="nes-pointer">About</span></a><a target="_blank" href="https://www.codedex.io/blog"><span class="nes-pointer">Blog</span></a><a target="_blank" href="https://codedex.myshopify.com/"><span class="nes-pointer">Shop</span></a><a target="_blank" href="https://www.codedex.io/community"><span class="nes-pointer">Community</span></a><a target="_blank" href="https://codedex.notion.site/Welcome-to-the-Cod-dex-Help-Center-c8afe2966ea9490d9377bce826d22eb7"><span class="nes-pointer">Help Center</span></a><a target="_blank" href="https://www.codedex.io/pricing"><span class="nes-pointer">Pricing</span></a></div></div><div class="sc-9c9aac60-0 kHqbpb"><div class="row-title"><p>PRACTICE</p></div><div class="links"><a target="_blank" href="https://www.codedex.io/challenges"><span class="nes-pointer">Challenges</span></a><a target="_blank" href="https://www.codedex.io/projects"><span class="nes-pointer">Projects</span></a><a target="_blank" href="https://www.codedex.io/30-nites-of-code"><span class="nes-pointer">#30NitesOfCode</span></a></div></div><div class="sc-9c9aac60-0 kHqbpb"><div class="row-title"><p>Learn</p></div><div class="links"><a target="_blank" href="https://www.codedex.io/courses"><span class="nes-pointer">All Courses</span></a><a target="_blank" href="https://www.codedex.io/python"><span class="nes-pointer">Python</span></a><a target="_blank" href="https://www.codedex.io/intermediate-python"><span class="nes-pointer">Intermediate Python</span></a><a target="_blank" href="https://www.codedex.io/numpy"><span class="nes-pointer">NumPy</span></a><a target="_blank" href="https://www.codedex.io/sql"><span class="nes-pointer">SQL</span></a><a target="_blank" href="https://www.codedex.io/html"><span class="nes-pointer">HTML</span></a><a target="_blank" href="https://www.codedex.io/css"><span class="nes-pointer">CSS</span></a></div></div><div class="sc-9c9aac60-0 ffGwcQ"><div class="row-title"><p></p></div><div class="links"><a target="_blank" href="https://www.codedex.io/javascript"><span class="nes-pointer">JavaScript</span></a><a target="_blank" href="https://www.codedex.io/intermediate-javascript"><span class="nes-pointer">Intermediate JavaScript</span></a><a target="_blank" href="https://www.codedex.io/react"><span class="nes-pointer">React</span></a><a target="_blank" href="https://www.codedex.io/command-line"><span class="nes-pointer">Command Line</span></a><a target="_blank" href="https://www.codedex.io/git-github"><span class="nes-pointer">Git &amp; GitHub</span></a><a target="_blank" href="https://www.codedex.io/p5js"><span class="nes-pointer">p5.js</span></a><a target="_blank" href="https://www.codedex.io/cpp"><span class="nes-pointer">C++</span></a><a target="_blank" href="https://www.codedex.io/java"><span class="nes-pointer">Java</span></a></div></div></div><div class="sc-8ffb4ac6-0 kYJBlG"><div class="footer-bottom-text"><p>© 2024 Niteowl, Inc.</p><a target="_blank" rel="noreferrer" href="https://www.codedex.io/terms"><p class="nes-pointer">Terms</p></a><a target="_blank" rel="noreferrer" href="https://www.codedex.io/privacy"><p class="nes-pointer">Privacy Policy</p></a></div><div class="social-logo-container"><a target="_blank" href="https://www.instagram.com/codedex.io"><i class="nes-icon instagram icon-hover nes-pointer"></i></a><a target="_blank" href="https://twitter.com/codedex_io"><i class="nes-icon twitter icon-hover nes-pointer"></i></a><a target="_blank" href="https://github.com/codedex-io"><i class="nes-icon github icon-hover nes-pointer"></i></a><a target="_blank" href="https://www.youtube.com/@codedex"><i class="nes-icon youtube icon-hover nes-pointer"></i></a><a target="_blank" href="https://www.linkedin.com/company/codedex"><i class="nes-icon linkedin icon-hover nes-pointer"></i></a><a target="_blank" href="https://www.tiktok.com/@codedex.io"><i class="nes-icon tiktok icon-hover nes-pointer"><img src="./Codédex _ Generate a Blog with OpenAI_files/tiktok_logo.png" alt="tiktok logo" style="margin-bottom: 0.5rem;"></i></a><a target="_blank" href="https://discord.gg/vSKEhP9fY2"><i class="nes-icon icon-hover nes-pointer"><img src="./Codédex _ Generate a Blog with OpenAI_files/discord.png" alt="tiktok logo" style="margin-bottom: 0.5rem; transform: scale(1.3);"></i></a></div></div></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"projectData":{"source":{"scope":{},"frontmatter":{},"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    a: \"a\",\n    span: \"span\",\n    p: \"p\",\n    strong: \"strong\",\n    br: \"br\",\n    h2: \"h2\",\n    em: \"em\",\n    blockquote: \"blockquote\",\n    h3: \"h3\",\n    code: \"code\",\n    pre: \"pre\",\n    ul: \"ul\",\n    li: \"li\",\n    ol: \"ol\",\n    img: \"img\"\n  }, _provideComponents(), props.components), {BannerImage, AuthorAvatar, RoundedImage} = _components;\n  if (!AuthorAvatar) _missingMdxReference(\"AuthorAvatar\", true);\n  if (!BannerImage) _missingMdxReference(\"BannerImage\", true);\n  if (!RoundedImage) _missingMdxReference(\"RoundedImage\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(BannerImage, {\n      link: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png\",\n      description: \"Title Image\",\n      uid: true,\n      cl: \"for-sidebar\"\n    }), \"\\n\", _jsxs(_components.h1, {\n      id: \"generate-a-blog-with-openai\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#generate-a-blog-with-openai\",\n        children: _jsx(_components.span, {})\n      }), \"Generate a Blog with OpenAI\"]\n    }), \"\\n\", _jsx(AuthorAvatar, {\n      author_name: \"Asiqur Rahman\",\n      author_avatar: \"/images/projects/authors/asiqur_rahman.png\",\n      username: \"asiqur\",\n      uid: true\n    }), \"\\n\", _jsx(BannerImage, {\n      link: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png\",\n      description: \"Title Image\",\n      uid: true\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Prerequisites:\"\n      }), \" Python fundamentals\", _jsx(_components.br, {}), \"\\n\", _jsx(_components.strong, {\n        children: \"Versions:\"\n      }), \" Python 3.10, python-dotenv 0.21.0, openai 1.0.0\", _jsx(_components.br, {}), \"\\n\", _jsx(_components.strong, {\n        children: \"Read Time:\"\n      }), \" 60 minutes\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"introduction\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#introduction\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Introduction\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"Artificial Intelligence (AI)\"\n      }), \" is becoming the next big technology to harness. From smart fridges to self-driving cars, AI is implemented in almost everything you can think of. So let's get ahead of the pack and learn how we can leverage the power of AI with Python and OpenAI.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In this tutorial, we'll learn how to create a blog generator with \", _jsx(_components.a, {\n        href: \"https://openai.com/api/\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"GPT-3\"\n      }), \", an AI model provided by \", _jsx(_components.a, {\n        href: \"https://www.openai.com\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"OpenAI\"\n      }), \". The generator will read a topic to talk about as the input, and GPT-3 will return us a paragraph about that topic as the output.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So AI will be \\\"writing\\\" stuff for us. Say goodbye to writer's block!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"But wait, hold on! Artificial intelligence?! AI models?! This must be complicated to code. 😵\"\n    }), \"\\n\", _jsx(RoundedImage, {\n      link: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/calculation-math.gif\",\n      description: \"meme\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Nope, it's easier than you think. It takes around 25 lines of Python code!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The final result will look something like this:\"\n    }), \"\\n\", _jsx(RoundedImage, {\n      link: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/generator-demo.gif\",\n      description: \"generator demo\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.em, {\n        children: \"Who knows, maybe this entire project was written by the generator we're about to create. 👀\"\n      })\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"what-is-gpt-3\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#what-is-gpt-3\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" What is GPT-3?\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://en.wikipedia.org/wiki/GPT-3\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"GPT-3\"\n      }), \" is an AI model released by OpenAI in 2020. An AI model is a program trained on a bunch of data to perform a specific task. In this case, GPT-3 was trained to speak like a human and predict what comes next given the context of a sentence, with its training dataset being 45 terabytes of text (!) from the internet.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsxs(_components.p, {\n        children: [\"For reference, if you had to keep writing until your paper hits 45 terabytes in size, you would have to write \", _jsx(_components.a, {\n          href: \"https://www.techtarget.com/searchstorage/definition/How-many-bytes-for\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"22,500,000,000\"\n        }), \" pages worth of plain text.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Since GPT-3 was trained on internet data, it knows what the internet knows (not everything of course). This means that if we were to give GPT-3 a sentence, it would be able to predict what comes next in that sentence with high accuracy, based on all the text that was used to train it.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now we know what we'll be working with, let's build the program!\"\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"setting-up\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#setting-up\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Setting Up\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"openai-account\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#openai-account\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" OpenAI Account\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Before we do anything, we need an \", _jsx(_components.a, {\n        href: \"https://openai.com/api\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"OpenAI\"\n      }), \" account. We'll need this to access an API key for using GPT-3. Note that OpenAI no longer offers free credits, so you'll need to purchase at least 5 dollars worth of credits to start using the API.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/API\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"API (Application Programming Interface)\"\n        }), \" is a way for two computers to communicate with each other. Think of it like two friends texting back and forth. An API key is a code we receive to access the API. Think of it like an important password, so don’t share it with others!\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Go to \", _jsx(_components.a, {\n        href: \"http://www.openai.com\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"www.openai.com\"\n      }), \" and sign up for an OpenAI account.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"After you've created an account, click on your profile picture on the top right, then click \\\"View API keys\\\" to access your API key. You should see \", _jsx(_components.a, {\n        href: \"https://beta.openai.com/account/api-keys\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"this page\"\n      }), \" and it should look like:\"]\n    }), \"\\n\", _jsx(RoundedImage, {\n      link: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/api-key.png\",\n      description: \"API Key\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we know where the API key is located, let's keep it in mind for later.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"python-setup\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#python-setup\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Python Setup\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For this project, we'll need \", _jsx(_components.a, {\n        href: \"https://www.python.org/downloads/\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"Python 3\"\n      }), \" and \", _jsx(_components.a, {\n        href: \"https://pip.pypa.io/en/stable/\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"pip\"\n      }), \" (package installer) installed.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Assuming that we have those two installed, let's open up the code editor of our choice (we recommend \", _jsx(_components.a, {\n        href: \"https://code.visualstudio.com\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"VS Code\"\n      }), \") and create a new file called \", _jsx(_components.strong, {\n        children: \"blog_generator.py\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Note\"\n      }), \": You can name this file anything except for \", _jsx(_components.strong, {\n        children: \"openai.py\"\n      }), \", since the name will clash with a package we'll be installing.\"]\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"beginning-the-project\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#beginning-the-project\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Beginning the Project\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At the core of this project, all we'll be doing is sending data with instructions to a server owned by OpenAI, then receiving a response back from that server and displaying it.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"install-openai\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#install-openai\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Install openai\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We'll be interacting with GPT-3 model using a python package called \", _jsx(_components.code, {\n        children: \"openai\"\n      }), \". This package consists of methods that can connect to the internet and grant us access to the GPT-3 model hosted by OpenAI, the company.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"To install \", _jsx(_components.code, {\n        children: \"openai\"\n      }), \", all we have to do is run the following command in our terminal:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-sh\",\n        children: \"pip install openai\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can now use this package by importing it into our \", _jsx(_components.strong, {\n        children: \"blog_generator.py\"\n      }), \" file like so:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" openai\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"authorize-api-key\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#authorize-api-key\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Authorize API Key\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Before we can work with GPT-3 we need to set our API key in the \", _jsx(_components.code, {\n        children: \"openai\"\n      }), \" module. Remember, the API key is what gives us access to GPT-3; it authorizes us and says we're allowed to use this API.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can set our API key by extending a method in the \", _jsx(_components.code, {\n        children: \"openai\"\n      }), \" module called \", _jsx(_components.code, {\n        children: \"api_key\"\n      }), \":\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"openai.api_key = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Your_API_Key'\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The method will take in the API key as a string. Remember, your API key is located in your \", _jsx(_components.a, {\n        href: \"https://beta.openai.com/account/api-keys\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"OpenAI account\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So far, the code should look like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" openai\\n\\nopenai.api_key = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk'\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Fill in your own key\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"the-core-function\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#the-core-function\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" The Core Function\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we have access to GPT-3, we can get to the meat of the application, which is creating a function that takes in a prompt as user input and returns a paragraph about that prompt.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That function will look like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_blog\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"paragraph_topic\"\n        }), \"):\\n  response = openai.completions.create(\\n    model = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'gpt-3.5-turbo-instruct'\"\n        }), \",\\n    prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph about the following topic. '\"\n        }), \" + paragraph_topic,\\n    max_tokens = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"400\"\n        }), \",\\n    temperature = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.3\"\n        }), \"\\n  )\\n\\n  retrieve_blog = response.choices[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].text\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" retrieve_blog\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's break down this function and see what's going on here.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"First, we defined a function called \", _jsx(_components.code, {\n        children: \"generate_blog()\"\n      }), \". There's a single parameter called \", _jsx(_components.code, {\n        children: \"paragraph_topic\"\n      }), \", which will be the topic used to generate the paragraph:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_blog\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"paragraph_topic\"\n        }), \"):\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# The code inside\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And let's go inside the function. Here's the first part:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_blog\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"paragraph_topic\"\n        }), \"):\\n  response = openai.completions.create(\\n    model = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'gpt-3.5-turbo-instruct'\"\n        }), \",\\n    prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph about the following topic. '\"\n        }), \" + paragraph_topic,\\n    max_tokens = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"400\"\n        }), \",\\n    temperature = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.3\"\n        }), \"\\n  )\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is the bulk of our function and where we use GPT-3. We created a variable called \", _jsx(_components.code, {\n        children: \"response\"\n      }), \" to store the response generated by the output of the \", _jsx(_components.code, {\n        children: \"completions.create()\"\n      }), \" method call in our \", _jsx(_components.code, {\n        children: \"openai\"\n      }), \" module.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"GPT-3 has different endpoints for specific purposes, but for our goal, we'll use the \", _jsx(_components.a, {\n        href: \"https://beta.openai.com/docs/api-reference/completions\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"completion\"\n      }), \" endpoint. The completion endpoint will generate text depending on the provided prompt. You can read about the different endpoints in the \", _jsx(_components.a, {\n        href: \"https://beta.openai.com/docs/introduction\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"documentation\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we have access to the completion endpoint, we need to specify a few things, The first one being:\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"model\"\n      }), \": The model parameter will take in the model we want to use. OpenAI offers several models with different capabilities. For this tutorial, we are using \", _jsx(_components.code, {\n        children: \"gpt-3.5-turbo-instruct\"\n      }), \" to provide clear and reliable examples.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Syntax and capabilities varies between models. You can read more about the available models in the \", _jsx(_components.a, {\n        href: \"https://platform.openai.com/docs/models\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"documentation\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph about the following topic. '\"\n        }), \" + paragraph_topic,\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"prompt\"\n      }), \": This is where we design the main instructions for GPT-3. This parameter will take in our \", _jsx(_components.code, {\n        children: \"paragraph_topic\"\n      }), \" argument, but before that, we can tell GPT-3 what to do with that argument. Currently, we are instructing GPT-3 to \", _jsx(_components.code, {\n        children: \"Write a paragraph about the following topic\"\n      }), \". GPT-3 will try its best to follow this instruction and return us a paragraph.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"GPT-3 is very flexible; if the initial string is changed to \", _jsx(_components.code, {\n        children: \"Write a blog outline about the following topic\"\n      }), \", it will give us an outline instead of a normal paragraph. You can later play around with this by telling the model exactly what it should generate and seeing what interesting responses you get.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"max_tokens = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"400\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"tokens\"\n      }), \": The token number decides how long the response is going to be. A larger token number will produce a longer response. By setting a specific number, we're saying that the response can't go past this token size. The way tokens are counted towards a response is a bit complex, but you can read this \", _jsx(_components.a, {\n        href: \"https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"article\"\n      }), \" by OpenAI that explains how token size is calculated.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Roughly 75 words is about 100 tokens. A paragraph has 300 words on average. So, 400 tokens is about the length of a normal paragraph. The model \", _jsx(_components.code, {\n        children: \"gpt-3.5-turbo-instruct\"\n      }), \" has a token limit of 4,096.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"temperature = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.3\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"temperature\"\n      }), \": Temperature determines the randomness of a response. A higher temperature will produce a more creative response, while a lower temperature will produce a more well-defined response.\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.code, {\n          children: \"0\"\n        }), \": The same response every time.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.code, {\n          children: \"1\"\n        }), \": A different response every time, even if it's the same prompt.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"There are plenty of other fields that we can specify to fine-tune the model even more, which you can read in the \", _jsx(_components.a, {\n        href: \"https://beta.openai.com/docs/api-reference/completions/create\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"documentation\"\n      }), \", but for now, these are the four fields we need to concern ourselves with.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Now that we have our model setup, we can run our function, and the following things will happen:\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"First, the \", _jsx(_components.code, {\n          children: \"openai\"\n        }), \" module will take our API key, along with the fields we specified in the \", _jsx(_components.code, {\n          children: \"response\"\n        }), \" variable, and make a request to the completion endpoint.\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"OpenAI will then verify that we're allowed to use GPT-3 by verifying our API key.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"After verification, GPT-3 will use the specified fields to produce a response.\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"The produced response will be returned back in the form of an object and stored in the \", _jsx(_components.code, {\n          children: \"response\"\n        }), \" variable.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That returned object will look like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-swift\",\n        children: [\"{\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"choices\\\"\"\n        }), \": [\\n    {\\n      \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"finish_reason\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"stop\\\"\"\n        }), \",\\n      \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"index\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \",\\n      \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"logprobs\\\"\"\n        }), \": null,\\n      \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"text\\\"\"\n        }), \": \", _jsxs(_components.span, {\n          className: \"hljs-string\",\n          children: [\"\\\"\", _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"\\\\n\"\n          }), _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"\\\\n\"\n          }), \"Python is a programming language with many features, such as an intuitive syntax and powerful data structures. It was created in the late 1980s by Guido van Rossum, with the goal of providing a simple yet powerful scripting language. Python has since become one of the most popular programming languages, with a wide range of applications in fields such as web development, scientific computing, and artificial intelligence.\\\"\"]\n        }), \"\\n    }\\n  ],\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"created\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1664302504\"\n        }), \",\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"id\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"cmpl-5v9OiMOjRyoyypRQWAdpyAtjtgVev\\\"\"\n        }), \",\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"model\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"gpt-3.5-turbo-instruct\\\"\"\n        }), \",\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"object\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"text_completion\\\"\"\n        }), \",\\n  \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"usage\\\"\"\n        }), \": {\\n    \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"completion_tokens\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"80\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"prompt_tokens\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"19\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"total_tokens\\\"\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"99\"\n        }), \"\\n  }\\n}\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We’re provided with tons of information about the response, but the only thing we care about is the \", _jsx(_components.code, {\n        children: \"text\"\n      }), \" field containing generated text.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can access the value in the \", _jsx(_components.code, {\n        children: \"text\"\n      }), \" field like so:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-ini\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"retrieve_blog\"\n        }), \" = response.choices[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].text\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Finally, we return the \", _jsx(_components.code, {\n        children: \"retrieve_blog\"\n      }), \" variable which holds the paragraph we just dug out of the dictionary.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-kotlin\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" retrieve_blog\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Whoah! Let's take a moment and breathe. That was a lot we just covered. Let's give ourselves a pat on the back as we're 90% done with the application.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can test to see if our code works so far by printing out the \", _jsx(_components.code, {\n        children: \"generate_blog()\"\n      }), \" function we just created, giving it a topic to write about, and seeing the response we get.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \"(generate_blog(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Why NYC is better than your city.'\"\n        }), \"))\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here's the complete code so far:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" openai\\n\\nopenai.api_key = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk'\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Fill in your own key\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_blog\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"paragraph_topic\"\n        }), \"):\\n  response = openai.completions.create(\\n    model = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'gpt-3.5-turbo-instruct'\"\n        }), \",\\n    prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph about the following topic. '\"\n        }), \" + paragraph_topic,\\n    max_tokens = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"400\"\n        }), \",\\n    temperature = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.3\"\n        }), \"\\n  )\\n\\n  retrieve_blog = response.choices[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].text\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" retrieve_blog\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \"(generate_blog(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Why NYC is better than your city.'\"\n        }), \"))\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And boom, after 2-3 seconds, it should spit out a paragraph like this:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/output-nyc.png\",\n        alt: \"Output: NYC\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Try running the code a couple more times; the output should be different every time! 🤯\"\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"multiple-paragraphs\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#multiple-paragraphs\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Multiple Paragraphs\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Right now, if we run our code, we'll only be able to generate one paragraph worth of text. Remember, we're trying to create a blog generator, and a blog has multiple sections, with each paragraph having a different topic.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's add some additional code to generate as many paragraphs as we want, with each paragraph discussing a different topic:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"keep_writing = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" keep_writing:\\n  answer = \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"input\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph? Y for yes, anything else for no. '\"\n        }), \")\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" (answer == \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Y'\"\n        }), \"):\\n    paragraph_topic = \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"input\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'What should this paragraph talk about? '\"\n        }), \")\\n    \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \"(generate_blog(paragraph_topic))\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"else\"\n        }), \":\\n    keep_writing = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"False\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"First, we defined a variable called \", _jsx(_components.code, {\n        children: \"keep_writing\"\n      }), \", to use as a boolean value for the following \", _jsx(_components.code, {\n        children: \"while\"\n      }), \" loop.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In the \", _jsx(_components.code, {\n        children: \"while\"\n      }), \" loop, we created an \", _jsx(_components.code, {\n        children: \"answer\"\n      }), \" variable that will take in an input from the user using the built-in \", _jsx(_components.code, {\n        children: \"input()\"\n      }), \" function.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We then created an \", _jsx(_components.code, {\n        children: \"if\"\n      }), \" statement that will either continue the loop or stop the loop.\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"If the input from the user is \", _jsx(_components.code, {\n          children: \"Y\"\n        }), \", then we will ask the user what topic they want to generate text about, storing that value in a variable called \", _jsx(_components.code, {\n          children: \"paragraph_topic\"\n        }), \". Then we will execute and print the \", _jsx(_components.code, {\n          children: \"generate_blog()\"\n        }), \" function using the \", _jsx(_components.code, {\n          children: \"parapgraph_topic\"\n        }), \" variable as its argument.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"Else, we will stop the loop by assigning the \", _jsx(_components.code, {\n          children: \"keep_writing\"\n        }), \" variable to \", _jsx(_components.code, {\n          children: \"False\"\n        }), \".\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With that complete, we can now write as many paragraphs as we want by running the program once!\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"rate-limit\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#rate-limit\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Rate Limit\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Since we're using a \", _jsx(_components.code, {\n        children: \"while\"\n      }), \" loop, we have the potential to be rate limited.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsxs(_components.p, {\n        children: [_jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Rate_limiting\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"Rate limit\"\n        }), \" is the number of API calls an app or user can make within a given time period.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is normally done to protect the API from abuse or \", _jsx(_components.a, {\n        href: \"https://en.wikipedia.org/wiki/Denial-of-service_attack\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"DoS\"\n      }), \" attacks.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For GPT-3, the rate limit is 20 requests per minute. As long as we don't run the function that fast, we'll be fine. But in a rare case that it does occur, GPT-3 will stop producing responses and make us wait a minute to produce another response.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"credit-limit\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#credit-limit\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Credit Limit\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"By this point, if you have been playing with the API nonstop, there's a chance that you might have exceeded your purchased credit limit. The following error is thrown when that happens:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-bash\",\n        children: \"openai.error.RateLimitError:  \\nYou exceeded your current quota, please check your plan and billing details.\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"If that's the case, go to OpenAI's \", _jsx(_components.a, {\n        href: \"https://platform.openai.com/settings/organization/billing/overview\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"Billing overview\"\n      }), \" page and purchase additional credits.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's take another breather. We're almost done!\"\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"securing-our-app\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#securing-our-app\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Securing Our App\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's think about this for a minute. We created this amazing application and want to share it with the world, right? Well, when we deploy it to the web or share it with our friends, they'll be able to see every piece of code in the program. That's where the issue lies!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"At the beginning of this article, we created an account with OpenAI and were assigned an API key. Remember, this API key is what gives us access to GPT-3. Since GPT-3 is a paid service, the API key is also used to track usage and charge us accordingly. So what happens when someone knows our API key? They'll be able to use the service with our key, and we'll be the one charged, potentially thousands of dollars!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In order to protect ourselves, we need to hide the API key in our code but still be able to use it. Let's see how we can do that.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"install-python-dotenv\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#install-python-dotenv\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Install \", _jsx(_components.code, {\n        children: \"python-dotenv\"\n      })]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://pypi.org/project/python-dotenv\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: _jsx(_components.code, {\n          children: \"python-dotenv\"\n        })\n      }), \" is a package that allows us to create and use environment variables without having to set them in the operating system manually.\"]\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Environment variables are variables whose values are set outside the program, typically in the operating system.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can install \", _jsx(_components.code, {\n        children: \"python-dotenv\"\n      }), \" by running the following command in the terminal:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-sh\",\n        children: \"pip install python-dotenv\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"env-file\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#env-file\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" .env File\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Then in our project's root directory, create a file called \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \". This file will hold our environment variable.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Open up the \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \" file and create a variable like so:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-ini\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"API_KEY\"\n        }), \"=\u003cYour_API_Key\u003e\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The variable will take in our API key without any quotation marks or spaces. Remember to name this variable as \", _jsx(_components.code, {\n        children: \"API_KEY\"\n      }), \" only.\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"python-file\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#python-file\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" Python File\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now that we have our environment variable set, let's open up the \", _jsx(_components.strong, {\n        children: \"blog_generator.py\"\n      }), \" file, and paste this code under \", _jsx(_components.code, {\n        children: \"import openai\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" dotenv \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" dotenv_values\\n\\nconfig = dotenv_values(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\".env\\\"\"\n        }), \")\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"First, we've imported a method called \", _jsx(_components.code, {\n        children: \"dotenv_values\"\n      }), \" from the module.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The \", _jsx(_components.code, {\n        children: \"dotenv_values()\"\n      }), \" will take in the path to the \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \" file and return us a dictionary with all the variables in the \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \" file. We then created a \", _jsx(_components.code, {\n        children: \"config\"\n      }), \" variable to hold that dictionary.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, all we have to do is replace the exposed API key with the environment variable in the \", _jsx(_components.code, {\n        children: \"config\"\n      }), \" dictionary like so:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [\"openai.api_key = config[\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'API_KEY'\"\n        }), \"]\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That's it! Our API key is now safe and hidden from the main code.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"Note\"\n      }), \": If you want to push your code to \", _jsx(_components.a, {\n        href: \"https://www.github.com\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"GitHub\"\n      }), \", you don't want to push the \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \" file as well. In the root directory of your project, create a file called \", _jsx(_components.strong, {\n        children: \".gitignore\"\n      }), \", and in the Git ignore file, type in \", _jsx(_components.code, {\n        children: \".env\"\n      }), \". This will prevent the file from being tracked by Git and ultimately pushed to GitHub.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"With all that set and done, we’re finished! The code should now look like this!\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"blog_generator.py\"\n      }), \" file:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-py\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"# Generate a Blog with OpenAI 📝\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" openai\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" dotenv \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" dotenv_values\\n\\nconfig = dotenv_values(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'.env'\"\n        }), \")\\n\\nopenai.api_key = config[\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'API_KEY'\"\n        }), \"]\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"def\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"generate_blog\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-params\",\n          children: \"paragraph_topic\"\n        }), \"):\\n  response = openai.completions.create(\\n    model = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'gpt-3.5-turbo-instruct'\"\n        }), \",\\n    prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph about the following topic. '\"\n        }), \" + paragraph_topic,\\n    max_tokens = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"400\"\n        }), \",\\n    temperature = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.3\"\n        }), \"\\n  )\\n  retrieve_blog = response.choices[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].text\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" retrieve_blog\\n\\nkeep_writing = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"True\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" keep_writing:\\n  answer = \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"input\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Write a paragraph? Y for yes, anything else for no. '\"\n        }), \")\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" (answer == \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Y'\"\n        }), \"):\\n    paragraph_topic = \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"input\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'What should this paragraph talk about? '\"\n        }), \")\\n    \", _jsx(_components.span, {\n          className: \"hljs-built_in\",\n          children: \"print\"\n        }), \"(generate_blog(paragraph_topic))\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"else\"\n        }), \":\\n    keep_writing = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"False\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \".env\"\n      }), \" file:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-bash\",\n        children: \"API_KEY=sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.h2, {\n      id: \"finish-line\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#finish-line\",\n        children: _jsx(_components.span, {\n          children: \"#\"\n        })\n      }), \" Finish Line\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Congrats, you just created a blog generator with OpenAI and Python! Throughout the project, we learned how to use GPT-3 to generate a paragraph, use a \", _jsx(_components.code, {\n        children: \"while\"\n      }), \" loop to create multiple paragraphs, and secure our app with a \", _jsx(_components.strong, {\n        children: \".env\"\n      }), \" file. 🙌\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"AI is expanding rapidly, and the first few to utilize it properly through services like GPT-3 will become the inovators in the field. Hope this project helps you understand it a bit more.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"And lastly, we would love to see what you build with this tutorial! Tag \", _jsx(_components.a, {\n        href: \"@codedex_io\",\n        children: \"@codedex_io\"\n      }), \" and \", _jsx(_components.a, {\n        href: \"https://twitter.com/openai\",\n        target: \"_blank\",\n        rel: \"nofollow noreferrer noopener\",\n        children: \"@openai\"\n      }), \" on Twitter if you make something cool!\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"more-resources\",\n      children: [_jsx(_components.a, {\n        \"aria-hidden\": \"true\",\n        tabIndex: \"-1\",\n        href: \"#more-resources\",\n        children: _jsx(_components.span, {\n          children: \"##\"\n        })\n      }), \" More Resources\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://github.com/codedex-io/projects/blob/main/projects/generate-a-blog-with-openai/blog_generator.py\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"Solution on GitHub\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://openai.com\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"OpenAI\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://pypi.org/project/python-dotenv\",\n          target: \"_blank\",\n          rel: \"nofollow noreferrer noopener\",\n          children: \"python-dotenv\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n"},"frontMatter":{"author":"Asiqur Rahman","link":"generate-a-blog-with-openai","description":"Learn how to build a blog generator with OpenAI's GPT-3 and Python and never experience writer's block again.","title":"Generate a Blog with OpenAI","tags":["intermediate","python"],"datePublished":"Wed, 12 Oct 2022 00:00:00 GMT","bannerImage":"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png","uid":"jHMm1llOHzRoM1tJpZK1dvqD0B92","header":"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/seo.png","likes":0,"published":true,"content":"\n\u003cBannerImage link=\"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png\" description=\"Title Image\" uid={true} cl=\"for-sidebar\"/\u003e\n\n# Generate a Blog with OpenAI\n\n\u003cAuthorAvatar\n  author_name=\"Asiqur Rahman\"\n  author_avatar=\"/images/projects/authors/asiqur_rahman.png\"\n  username=\"asiqur\"\n  uid={true}\n/\u003e\n\n\u003cBannerImage link=\"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/header.png\" description=\"Title Image\" uid={true}/\u003e\n\n**Prerequisites:** Python fundamentals  \n**Versions:** Python 3.10, python-dotenv 0.21.0, openai 1.0.0  \n**Read Time:** 60 minutes\n\n## Introduction\n\n[Artificial Intelligence (AI)](https://en.wikipedia.org/wiki/Artificial_intelligence) is becoming the next big technology to harness. From smart fridges to self-driving cars, AI is implemented in almost everything you can think of. So let's get ahead of the pack and learn how we can leverage the power of AI with Python and OpenAI.\n\nIn this tutorial, we'll learn how to create a blog generator with [GPT-3](https://openai.com/api/), an AI model provided by [OpenAI](https://www.openai.com). The generator will read a topic to talk about as the input, and GPT-3 will return us a paragraph about that topic as the output. \n\nSo AI will be \"writing\" stuff for us. Say goodbye to writer's block!\n\nBut wait, hold on! Artificial intelligence?! AI models?! This must be complicated to code. 😵\n\n\u003cRoundedImage link=\"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/calculation-math.gif\" description=\"meme\"/\u003e\n\nNope, it's easier than you think. It takes around 25 lines of Python code!\n\nThe final result will look something like this:\n\n\u003cRoundedImage link=\"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/generator-demo.gif\" description=\"generator demo\"/\u003e\n\n_Who knows, maybe this entire project was written by the generator we're about to create. 👀_\n\n## What is GPT-3?\n\n[GPT-3](https://en.wikipedia.org/wiki/GPT-3) is an AI model released by OpenAI in 2020. An AI model is a program trained on a bunch of data to perform a specific task. In this case, GPT-3 was trained to speak like a human and predict what comes next given the context of a sentence, with its training dataset being 45 terabytes of text (!) from the internet. \n\n\u003e For reference, if you had to keep writing until your paper hits 45 terabytes in size, you would have to write [22,500,000,000](https://www.techtarget.com/searchstorage/definition/How-many-bytes-for) pages worth of plain text. \n\nSince GPT-3 was trained on internet data, it knows what the internet knows (not everything of course). This means that if we were to give GPT-3 a sentence, it would be able to predict what comes next in that sentence with high accuracy, based on all the text that was used to train it.\n\nNow we know what we'll be working with, let's build the program!\n\n## Setting Up\n\n### OpenAI Account\n\nBefore we do anything, we need an [OpenAI](https://openai.com/api) account. We'll need this to access an API key for using GPT-3. Note that OpenAI no longer offers free credits, so you'll need to purchase at least 5 dollars worth of credits to start using the API.\n\n\u003e [API (Application Programming Interface)](https://en.wikipedia.org/wiki/API) is a way for two computers to communicate with each other. Think of it like two friends texting back and forth. An API key is a code we receive to access the API. Think of it like an important password, so don’t share it with others!\n\nGo to www.openai.com and sign up for an OpenAI account.\n\nAfter you've created an account, click on your profile picture on the top right, then click \"View API keys\" to access your API key. You should see [this page](https://beta.openai.com/account/api-keys) and it should look like:\n\n\u003cRoundedImage link=\"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/api-key.png\" description=\"API Key\"/\u003e\n\nNow that we know where the API key is located, let's keep it in mind for later.\n\n### Python Setup\n\nFor this project, we'll need [Python 3](https://www.python.org/downloads/) and [pip](https://pip.pypa.io/en/stable/) (package installer) installed.\n\nAssuming that we have those two installed, let's open up the code editor of our choice (we recommend [VS Code](https://code.visualstudio.com)) and create a new file called **blog_generator.py**.\n\n**Note**: You can name this file anything except for **openai.py**, since the name will clash with a package we'll be installing.\n\n\n## Beginning the Project\n\nAt the core of this project, all we'll be doing is sending data with instructions to a server owned by OpenAI, then receiving a response back from that server and displaying it.\n\n### Install openai\n\nWe'll be interacting with GPT-3 model using a python package called `openai`. This package consists of methods that can connect to the internet and grant us access to the GPT-3 model hosted by OpenAI, the company.\n\nTo install `openai`, all we have to do is run the following command in our terminal:\n\n```sh\npip install openai\n```\n\nWe can now use this package by importing it into our **blog_generator.py** file like so:\n\n```py\nimport openai\n```\n\n### Authorize API Key\n\nBefore we can work with GPT-3 we need to set our API key in the `openai` module. Remember, the API key is what gives us access to GPT-3; it authorizes us and says we're allowed to use this API.\n\nWe can set our API key by extending a method in the `openai` module called `api_key`:\n\n```py\nopenai.api_key = 'Your_API_Key'\n```\n\nThe method will take in the API key as a string. Remember, your API key is located in your [OpenAI account](https://beta.openai.com/account/api-keys).\n\nSo far, the code should look like this:\n\n```py\nimport openai\n\nopenai.api_key = 'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk' # Fill in your own key\n```\n\n## The Core Function\n\nNow that we have access to GPT-3, we can get to the meat of the application, which is creating a function that takes in a prompt as user input and returns a paragraph about that prompt. \n\nThat function will look like this:\n\n```py\ndef generate_blog(paragraph_topic):\n  response = openai.completions.create(\n    model = 'gpt-3.5-turbo-instruct',\n    prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,\n    max_tokens = 400,\n    temperature = 0.3\n  )\n\n  retrieve_blog = response.choices[0].text\n\n  return retrieve_blog\n```\n\nLet's break down this function and see what's going on here.\n\nFirst, we defined a function called `generate_blog()`. There's a single parameter called `paragraph_topic`, which will be the topic used to generate the paragraph:\n\n```py\ndef generate_blog(paragraph_topic):\n  # The code inside\n```\n\nAnd let's go inside the function. Here's the first part:\n\n```py\ndef generate_blog(paragraph_topic):\n  response = openai.completions.create(\n    model = 'gpt-3.5-turbo-instruct',\n    prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,\n    max_tokens = 400,\n    temperature = 0.3\n  )\n```\n\nThis is the bulk of our function and where we use GPT-3. We created a variable called `response` to store the response generated by the output of the `completions.create()` method call in our `openai` module. \n\nGPT-3 has different endpoints for specific purposes, but for our goal, we'll use the [completion](https://beta.openai.com/docs/api-reference/completions) endpoint. The completion endpoint will generate text depending on the provided prompt. You can read about the different endpoints in the [documentation](https://beta.openai.com/docs/introduction).\n\nNow that we have access to the completion endpoint, we need to specify a few things, The first one being:\n\n`model`: The model parameter will take in the model we want to use. OpenAI offers several models with different capabilities. For this tutorial, we are using `gpt-3.5-turbo-instruct` to provide clear and reliable examples.\n\nSyntax and capabilities varies between models. You can read more about the available models in the [documentation](https://platform.openai.com/docs/models).\n\n```py\nprompt = 'Write a paragraph about the following topic. ' + paragraph_topic,\n```\n\n`prompt`: This is where we design the main instructions for GPT-3. This parameter will take in our `paragraph_topic` argument, but before that, we can tell GPT-3 what to do with that argument. Currently, we are instructing GPT-3 to `Write a paragraph about the following topic`. GPT-3 will try its best to follow this instruction and return us a paragraph. \n\nGPT-3 is very flexible; if the initial string is changed to `Write a blog outline about the following topic`, it will give us an outline instead of a normal paragraph. You can later play around with this by telling the model exactly what it should generate and seeing what interesting responses you get.\n\n```py\nmax_tokens = 400\n```\n\n`tokens`: The token number decides how long the response is going to be. A larger token number will produce a longer response. By setting a specific number, we're saying that the response can't go past this token size. The way tokens are counted towards a response is a bit complex, but you can read this [article](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) by OpenAI that explains how token size is calculated.\n\nRoughly 75 words is about 100 tokens. A paragraph has 300 words on average. So, 400 tokens is about the length of a normal paragraph. The model `gpt-3.5-turbo-instruct` has a token limit of 4,096.\n\n```py\ntemperature = 0.3\n```\n\n`temperature`: Temperature determines the randomness of a response. A higher temperature will produce a more creative response, while a lower temperature will produce a more well-defined response.\n\n- `0`: The same response every time.\n- `1`: A different response every time, even if it's the same prompt.\n\nThere are plenty of other fields that we can specify to fine-tune the model even more, which you can read in the [documentation](https://beta.openai.com/docs/api-reference/completions/create), but for now, these are the four fields we need to concern ourselves with.\n\nNow that we have our model setup, we can run our function, and the following things will happen:\n\n1. First, the `openai` module will take our API key, along with the fields we specified in the `response` variable, and make a request to the completion endpoint.\n2. OpenAI will then verify that we're allowed to use GPT-3 by verifying our API key.\n3. After verification, GPT-3 will use the specified fields to produce a response.\n4. The produced response will be returned back in the form of an object and stored in the `response` variable.\n\nThat returned object will look like this:\n\n```\n{\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"\\n\\nPython is a programming language with many features, such as an intuitive syntax and powerful data structures. It was created in the late 1980s by Guido van Rossum, with the goal of providing a simple yet powerful scripting language. Python has since become one of the most popular programming languages, with a wide range of applications in fields such as web development, scientific computing, and artificial intelligence.\"\n    }\n  ],\n  \"created\": 1664302504,\n  \"id\": \"cmpl-5v9OiMOjRyoyypRQWAdpyAtjtgVev\",\n  \"model\": \"gpt-3.5-turbo-instruct\",\n  \"object\": \"text_completion\",\n  \"usage\": {\n    \"completion_tokens\": 80,\n    \"prompt_tokens\": 19,\n    \"total_tokens\": 99\n  }\n}\n```\n\nWe’re provided with tons of information about the response, but the only thing we care about is the `text` field containing generated text.\n\nWe can access the value in the `text` field like so:\n\n```\nretrieve_blog = response.choices[0].text\n```\n\nFinally, we return the `retrieve_blog` variable which holds the paragraph we just dug out of the dictionary.\n\n```\nreturn retrieve_blog\n```\n\nWhoah! Let's take a moment and breathe. That was a lot we just covered. Let's give ourselves a pat on the back as we're 90% done with the application.\n\nWe can test to see if our code works so far by printing out the `generate_blog()` function we just created, giving it a topic to write about, and seeing the response we get.\n\n```py\nprint(generate_blog('Why NYC is better than your city.'))\n```\n\nHere's the complete code so far:\n\n```py\nimport openai\n\nopenai.api_key = 'sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk' # Fill in your own key\n\ndef generate_blog(paragraph_topic):\n  response = openai.completions.create(\n    model = 'gpt-3.5-turbo-instruct',\n    prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,\n    max_tokens = 400,\n    temperature = 0.3\n  )\n\n  retrieve_blog = response.choices[0].text\n\n  return retrieve_blog\n\nprint(generate_blog('Why NYC is better than your city.'))\n```\n\nAnd boom, after 2-3 seconds, it should spit out a paragraph like this:\n\n![Output: NYC](https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/output-nyc.png)\n\nTry running the code a couple more times; the output should be different every time! 🤯\n\n\n## Multiple Paragraphs\n\nRight now, if we run our code, we'll only be able to generate one paragraph worth of text. Remember, we're trying to create a blog generator, and a blog has multiple sections, with each paragraph having a different topic.\n\nLet's add some additional code to generate as many paragraphs as we want, with each paragraph discussing a different topic:\n\n```py\nkeep_writing = True\n\nwhile keep_writing:\n  answer = input('Write a paragraph? Y for yes, anything else for no. ')\n  if (answer == 'Y'):\n    paragraph_topic = input('What should this paragraph talk about? ')\n    print(generate_blog(paragraph_topic))\n  else:\n    keep_writing = False\n```\n\nFirst, we defined a variable called `keep_writing`, to use as a boolean value for the following `while` loop.\n\nIn the `while` loop, we created an `answer` variable that will take in an input from the user using the built-in `input()` function.\n\nWe then created an `if` statement that will either continue the loop or stop the loop.\n\n- If the input from the user is `Y`, then we will ask the user what topic they want to generate text about, storing that value in a variable called `paragraph_topic`. Then we will execute and print the `generate_blog()` function using the `parapgraph_topic` variable as its argument.\n- Else, we will stop the loop by assigning the `keep_writing` variable to `False`.\n\nWith that complete, we can now write as many paragraphs as we want by running the program once!\n\n### Rate Limit\n\nSince we're using a `while` loop, we have the potential to be rate limited.\n\n\u003e [Rate limit](https://en.wikipedia.org/wiki/Rate_limiting) is the number of API calls an app or user can make within a given time period.\n\nThis is normally done to protect the API from abuse or [DoS](https://en.wikipedia.org/wiki/Denial-of-service_attack) attacks.\n\nFor GPT-3, the rate limit is 20 requests per minute. As long as we don't run the function that fast, we'll be fine. But in a rare case that it does occur, GPT-3 will stop producing responses and make us wait a minute to produce another response.\n\n### Credit Limit\n\nBy this point, if you have been playing with the API nonstop, there's a chance that you might have exceeded your purchased credit limit. The following error is thrown when that happens:\n\n```bash\nopenai.error.RateLimitError:  \nYou exceeded your current quota, please check your plan and billing details.\n```\n\nIf that's the case, go to OpenAI's [Billing overview](https://platform.openai.com/settings/organization/billing/overview) page and purchase additional credits.\n\nLet's take another breather. We're almost done!\n\n## Securing Our App\n\nLet's think about this for a minute. We created this amazing application and want to share it with the world, right? Well, when we deploy it to the web or share it with our friends, they'll be able to see every piece of code in the program. That's where the issue lies!\n\nAt the beginning of this article, we created an account with OpenAI and were assigned an API key. Remember, this API key is what gives us access to GPT-3. Since GPT-3 is a paid service, the API key is also used to track usage and charge us accordingly. So what happens when someone knows our API key? They'll be able to use the service with our key, and we'll be the one charged, potentially thousands of dollars!\n\nIn order to protect ourselves, we need to hide the API key in our code but still be able to use it. Let's see how we can do that.\n\n### Install `python-dotenv`\n\n[`python-dotenv`](https://pypi.org/project/python-dotenv) is a package that allows us to create and use environment variables without having to set them in the operating system manually.\n\n\u003e Environment variables are variables whose values are set outside the program, typically in the operating system.\n\nWe can install `python-dotenv` by running the following command in the terminal:\n\n```sh\npip install python-dotenv\n```\n\n### .env File\n\nThen in our project's root directory, create a file called **.env**. This file will hold our environment variable.\n\nOpen up the **.env** file and create a variable like so:\n\n```\nAPI_KEY=\u003cYour_API_Key\u003e\n```\n\nThe variable will take in our API key without any quotation marks or spaces. Remember to name this variable as `API_KEY` only.\n\n### Python File\n\nNow that we have our environment variable set, let's open up the **blog_generator.py** file, and paste this code under `import openai`.\n\n```py\nfrom dotenv import dotenv_values\n\nconfig = dotenv_values(\".env\")\n```\n\nFirst, we've imported a method called `dotenv_values` from the module.\n\nThe `dotenv_values()` will take in the path to the **.env** file and return us a dictionary with all the variables in the **.env** file. We then created a `config` variable to hold that dictionary.\n\nNow, all we have to do is replace the exposed API key with the environment variable in the `config` dictionary like so:\n\n```py\nopenai.api_key = config['API_KEY']\n```\n\nThat's it! Our API key is now safe and hidden from the main code.\n\n**Note**: If you want to push your code to [GitHub](https://www.github.com), you don't want to push the **.env** file as well. In the root directory of your project, create a file called **.gitignore**, and in the Git ignore file, type in `.env`. This will prevent the file from being tracked by Git and ultimately pushed to GitHub.\n\nWith all that set and done, we’re finished! The code should now look like this!\n\n**blog_generator.py** file:\n\n```py\n# Generate a Blog with OpenAI 📝\n\nimport openai\nfrom dotenv import dotenv_values\n\nconfig = dotenv_values('.env')\n\nopenai.api_key = config['API_KEY']\n\ndef generate_blog(paragraph_topic):\n  response = openai.completions.create(\n    model = 'gpt-3.5-turbo-instruct',\n    prompt = 'Write a paragraph about the following topic. ' + paragraph_topic,\n    max_tokens = 400,\n    temperature = 0.3\n  )\n  retrieve_blog = response.choices[0].text\n  return retrieve_blog\n\nkeep_writing = True\n\nwhile keep_writing:\n  answer = input('Write a paragraph? Y for yes, anything else for no. ')\n  if (answer == 'Y'):\n    paragraph_topic = input('What should this paragraph talk about? ')\n    print(generate_blog(paragraph_topic))\n  else:\n    keep_writing = False\n```\n\n**.env** file:\n\n```bash\nAPI_KEY=sk-jAjqdWoqZLGsh7nXf5i8T3BlbkFJ9CYRk\n```\n\n## Finish Line\n\nCongrats, you just created a blog generator with OpenAI and Python! Throughout the project, we learned how to use GPT-3 to generate a paragraph, use a `while` loop to create multiple paragraphs, and secure our app with a **.env** file. 🙌\n\nAI is expanding rapidly, and the first few to utilize it properly through services like GPT-3 will become the inovators in the field. Hope this project helps you understand it a bit more.\n\nAnd lastly, we would love to see what you build with this tutorial! Tag [@codedex_io](@codedex_io) and [@openai](https://twitter.com/openai) on Twitter if you make something cool!\n\n\n### More Resources\n\n- [Solution on GitHub](https://github.com/codedex-io/projects/blob/main/projects/generate-a-blog-with-openai/blog_generator.py)\n- [OpenAI](https://openai.com)\n- [python-dotenv](https://pypi.org/project/python-dotenv)\n","dateUpdated":"Fri, 03 Jan 2025 23:50:16 GMT"}},"metatags":{"title":"Codédex | Generate a Blog with OpenAI","description":"Learn how to build a blog generator with OpenAI's GPT-3 and Python and never experience writer's block again.","image":"https://raw.githubusercontent.com/codedex-io/projects/main/projects/generate-a-blog-with-openai/seo.png","og":{"type":"website","url":"https://www.codedex.io/projects/generate-a-blog-with-openai"},"twitter":{"card":"summary_large_image","site":"@codedex_io","creator":"@codedex_io"}}},"__N_SSG":true},"page":"/projects/[project]","query":{"project":"generate-a-blog-with-openai"},"buildId":"k4UaVcC8HAlLPX97ZHUNn","isFallback":false,"gsp":true,"locale":"en","locales":["en"],"defaultLocale":"en","scriptLoader":[]}</script><div data-rmiz-portal=""></div><style id="web-highlights-global-style-variables">:root { --wh-slate-50: #f8fafc;--wh-slate-100: #f1f5f9;--wh-slate-200: #e2e8f0;--wh-slate-300: #cbd5e1;--wh-slate-400: #94a3b8;--wh-slate-500: #64748b;--wh-slate-600: #475569;--wh-slate-700: #334155;--wh-slate-800: #1e293b;--wh-slate-900: #0f172a;--wh-slate-950: #020617;--wh-primary-50: rgb(187, 219, 204);--wh-primary-100: rgb(153, 208, 184);--wh-primary-200: rgb(120, 197, 164);--wh-primary-300: rgb(86, 186, 144);--wh-primary-400: rgb(53, 176, 125);--wh-primary-500: hsl(161, 100%, 35%);--wh-primary-600: hsl(161, 100%, 33%);--wh-primary-700: hsl(161, 100%, 31%);--wh-primary-800: hsl(161, 100%, 29%);--wh-primary-900: hsl(161, 100%, 25%);--wh-primary-950: hsl(161, 100%, 20%);--wh-secondary-50: hsl(218, 22%, 30%);--wh-secondary-100: hsl(218, 22%, 27%);--wh-secondary-200: hsl(218, 22%, 25%);--wh-secondary-300: hsl(218, 22%, 22%);--wh-secondary-400: hsl(218, 22%, 20%);--wh-secondary-500: hsl(218, 22%, 18%);--wh-secondary-600: hsl(218, 22%, 16%);--wh-secondary-700: hsl(218, 22%, 14%);--wh-secondary-800: hsl(218, 22%, 12%);--wh-secondary-900: hsl(218, 22%, 8%);--wh-secondary-950: hsl(218, 22%, 6%);--wh-gray-50: #f9fafb;--wh-gray-100: #f3f4f6;--wh-gray-200: #e5e7eb;--wh-gray-300: #d1d5db;--wh-gray-400: #9ca3af;--wh-gray-500: #6b7280;--wh-gray-600: #4b5563;--wh-gray-700: #374151;--wh-gray-800: #1f2937;--wh-gray-900: #111827;--wh-gray-950: #030712;--wh-zinc-50: #fafafa;--wh-zinc-100: #f4f4f5;--wh-zinc-200: #e4e4e7;--wh-zinc-300: #d4d4d8;--wh-zinc-400: #a1a1aa;--wh-zinc-500: #71717a;--wh-zinc-600: #52525b;--wh-zinc-700: #3f3f46;--wh-zinc-800: #27272a;--wh-zinc-900: #18181b;--wh-zinc-950: #09090b;--wh-neutral-50: #fafafa;--wh-neutral-100: #f5f5f5;--wh-neutral-200: #e5e5e5;--wh-neutral-300: #d4d4d4;--wh-neutral-400: #a3a3a3;--wh-neutral-500: #737373;--wh-neutral-600: #525252;--wh-neutral-700: #404040;--wh-neutral-800: #262626;--wh-neutral-900: #171717;--wh-neutral-950: #0a0a0a;--wh-stone-50: #fafaf9;--wh-stone-100: #f5f5f4;--wh-stone-200: #e7e5e4;--wh-stone-300: #d6d3d1;--wh-stone-400: #a8a29e;--wh-stone-500: #78716c;--wh-stone-600: #57534e;--wh-stone-700: #44403c;--wh-stone-800: #292524;--wh-stone-900: #1c1917;--wh-stone-950: #0c0a09;--wh-red-50: #fef2f2;--wh-red-100: #fee2e2;--wh-red-200: #fecaca;--wh-red-300: #fca5a5;--wh-red-400: #f87171;--wh-red-500: #ef4444;--wh-red-600: #dc2626;--wh-red-700: #b91c1c;--wh-red-800: #991b1b;--wh-red-900: #7f1d1d;--wh-red-950: #450a0a;--wh-orange-50: #fff7ed;--wh-orange-100: #ffedd5;--wh-orange-200: #fed7aa;--wh-orange-300: #fdba74;--wh-orange-400: #fb923c;--wh-orange-500: #f97316;--wh-orange-600: #ea580c;--wh-orange-700: #c2410c;--wh-orange-800: #9a3412;--wh-orange-900: #7c2d12;--wh-orange-950: #431407;--wh-amber-50: #fffbeb;--wh-amber-100: #fef3c7;--wh-amber-200: #fde68a;--wh-amber-300: #fcd34d;--wh-amber-400: #fbbf24;--wh-amber-500: #f59e0b;--wh-amber-600: #d97706;--wh-amber-700: #b45309;--wh-amber-800: #92400e;--wh-amber-900: #78350f;--wh-amber-950: #451a03;--wh-yellow-50: #fefce8;--wh-yellow-100: #fef9c3;--wh-yellow-200: #fef08a;--wh-yellow-300: #fde047;--wh-yellow-400: #facc15;--wh-yellow-500: #eab308;--wh-yellow-600: #ca8a04;--wh-yellow-700: #a16207;--wh-yellow-800: #854d0e;--wh-yellow-900: #713f12;--wh-yellow-950: #422006;--wh-lime-50: #f7fee7;--wh-lime-100: #ecfccb;--wh-lime-200: #d9f99d;--wh-lime-300: #bef264;--wh-lime-400: #a3e635;--wh-lime-500: #84cc16;--wh-lime-600: #65a30d;--wh-lime-700: #4d7c0f;--wh-lime-800: #3f6212;--wh-lime-900: #365314;--wh-lime-950: #1a2e05;--wh-green-50: #f0fdf4;--wh-green-100: #dcfce7;--wh-green-200: #bbf7d0;--wh-green-300: #86efac;--wh-green-400: #4ade80;--wh-green-500: #22c55e;--wh-green-600: #16a34a;--wh-green-700: #15803d;--wh-green-800: #166534;--wh-green-900: #14532d;--wh-green-950: #052e16;--wh-emerald-50: #ecfdf5;--wh-emerald-100: #d1fae5;--wh-emerald-200: #a7f3d0;--wh-emerald-300: #6ee7b7;--wh-emerald-400: #34d399;--wh-emerald-500: #10b981;--wh-emerald-600: #059669;--wh-emerald-700: #047857;--wh-emerald-800: #065f46;--wh-emerald-900: #064e3b;--wh-emerald-950: #022c22;--wh-teal-50: #f0fdfa;--wh-teal-100: #ccfbf1;--wh-teal-200: #99f6e4;--wh-teal-300: #5eead4;--wh-teal-400: #2dd4bf;--wh-teal-500: #14b8a6;--wh-teal-600: #0d9488;--wh-teal-700: #0f766e;--wh-teal-800: #115e59;--wh-teal-900: #134e4a;--wh-teal-950: #042f2e;--wh-cyan-50: #ecfeff;--wh-cyan-100: #cffafe;--wh-cyan-200: #a5f3fc;--wh-cyan-300: #67e8f9;--wh-cyan-400: #22d3ee;--wh-cyan-500: #06b6d4;--wh-cyan-600: #0891b2;--wh-cyan-700: #0e7490;--wh-cyan-800: #155e75;--wh-cyan-900: #164e63;--wh-cyan-950: #083344;--wh-sky-50: #f0f9ff;--wh-sky-100: #e0f2fe;--wh-sky-200: #bae6fd;--wh-sky-300: #7dd3fc;--wh-sky-400: #38bdf8;--wh-sky-500: #0ea5e9;--wh-sky-600: #0284c7;--wh-sky-700: #0369a1;--wh-sky-800: #075985;--wh-sky-900: #0c4a6e;--wh-sky-950: #082f49;--wh-blue-50: #eff6ff;--wh-blue-100: #dbeafe;--wh-blue-200: #bfdbfe;--wh-blue-300: #93c5fd;--wh-blue-400: #60a5fa;--wh-blue-500: #3b82f6;--wh-blue-600: #2563eb;--wh-blue-700: #1d4ed8;--wh-blue-800: #1e40af;--wh-blue-900: #1e3a8a;--wh-blue-950: #172554;--wh-indigo-50: #eef2ff;--wh-indigo-100: #e0e7ff;--wh-indigo-200: #c7d2fe;--wh-indigo-300: #a5b4fc;--wh-indigo-400: #818cf8;--wh-indigo-500: #6366f1;--wh-indigo-600: #4f46e5;--wh-indigo-700: #4338ca;--wh-indigo-800: #3730a3;--wh-indigo-900: #312e81;--wh-indigo-950: #1e1b4b;--wh-violet-50: #f5f3ff;--wh-violet-100: #ede9fe;--wh-violet-200: #ddd6fe;--wh-violet-300: #c4b5fd;--wh-violet-400: #a78bfa;--wh-violet-500: #8b5cf6;--wh-violet-600: #7c3aed;--wh-violet-700: #6d28d9;--wh-violet-800: #5b21b6;--wh-violet-900: #4c1d95;--wh-violet-950: #2e1065;--wh-purple-50: #faf5ff;--wh-purple-100: #f3e8ff;--wh-purple-200: #e9d5ff;--wh-purple-300: #d8b4fe;--wh-purple-400: #c084fc;--wh-purple-500: #a855f7;--wh-purple-600: #9333ea;--wh-purple-700: #7e22ce;--wh-purple-800: #6b21a8;--wh-purple-900: #581c87;--wh-purple-950: #3b0764;--wh-fuchsia-50: #fdf4ff;--wh-fuchsia-100: #fae8ff;--wh-fuchsia-200: #f5d0fe;--wh-fuchsia-300: #f0abfc;--wh-fuchsia-400: #e879f9;--wh-fuchsia-500: #d946ef;--wh-fuchsia-600: #c026d3;--wh-fuchsia-700: #a21caf;--wh-fuchsia-800: #86198f;--wh-fuchsia-900: #701a75;--wh-fuchsia-950: #4a044e;--wh-pink-50: #fdf2f8;--wh-pink-100: #fce7f3;--wh-pink-200: #fbcfe8;--wh-pink-300: #f9a8d4;--wh-pink-400: #f472b6;--wh-pink-500: #ec4899;--wh-pink-600: #db2777;--wh-pink-700: #be185d;--wh-pink-800: #9d174d;--wh-pink-900: #831843;--wh-pink-950: #500724;--wh-rose-50: #fff1f2;--wh-rose-100: #ffe4e6;--wh-rose-200: #fecdd3;--wh-rose-300: #fda4af;--wh-rose-400: #fb7185;--wh-rose-500: #f43f5e;--wh-rose-600: #e11d48;--wh-rose-700: #be123c;--wh-rose-800: #9f1239;--wh-rose-900: #881337;--wh-rose-950: #4c0519;--wh-primary-color: var(--wh-primary-500);--wh-primary-color-hover: #00a16e;--wh-primary-color-transparent: #00aa7424;--wh-primary-color-transparent-light: #00a8730f;--wh-primary-light: #53e3a6;--wh-primary-dark: #007f4b;--wh-primary-dark-hover: #017444;--wh-primary-shadow: #00b07841;--wh-primary-shadow-2: #00b07870;--wh-primary-border-color: #c8c8c870;--wh-warning-color: #ff5a1f;--wh-warning-color-light: #feecdc;--secondary-color: #3d4455;--secondary-color-hover: #3a4052;--secondary-color-transparent: #3d44556b;--secondary-light: #4c556d;--secondary-dark: #252934;--secondary-dark-hover: #191b22;--secondary-dark-transparent: #2e2d2d46;--highlight-color: #92ffaa;--error-color: #d62d4c;--error-color-light: #fde8e8;--error-info: #14854e;--success-color: #0e9f6e;--success-color-light: #def7ec;--font-color: #2f3237;--font-color-light: #626364;--font-color-dark: #252525;--wh-font-family: 'Inter', 'SF Pro Display', -apple-system, BlinkMacSystemFont,
  'Open Sans', 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell',
  'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif;--font-family: var(--wh-font-family);--font-size: 12px;--webhighlights-font-size: 12px;--link-color: #1d9bf0;--wh-form-active-color: #3b82f6;--wh-accent-blue: #1f6feb;--wh-mobile-breakpoint: 767px;--BREAKPOINT_XS: 575px;--BREAKPOINT_S: 767px;--BREAKPOINT_M: 991px;--BREAKPOINT_L: 1199px;--BREAKPOINT_XL: 1399px;--BREAKPOINT_XXL: 1699px;--wh-danger-color: var(--wh-red-600);--wh-danger-color-hover: var(--wh-red-700);--wh-font-size: 13px;--wh-blockquote-line-height: 1.3;--wh-bg-base: var(--wh-secondary-600);--wh-bg-base-hover: var(--wh-secondary-500);--wh-border-base: var(--wh-secondary-200);--wh-border-base-hover: var(--wh-secondary-100);--wh-border-base-strong: var(--wh-secondary-100);--wh-border-base-strong-hover: var(--wh-secondary-50);--wh-bg-base-hover-strong: var(--wh-secondary-300);--wh-bg-back: var(--wh-secondary-700);--wh-bg-back-strong: var(--wh-secondary-800);--wh-bg-back-strong-hover: var(--wh-secondary-900);--wh-bg-back-hover: var(--wh-secondary-600);--wh-bg-back-hover-strong: var(--wh-secondary-800);--wh-border-back: var(--wh-secondary-100);--wh-border-back-strong: var(--wh-secondary-50);--wh-bg-front: var(--wh-secondary-400);--wh-bg-front-strong: var(--wh-secondary-200);--wh-bg-front-strong-hover: var(--wh-secondary-100);--wh-bg-front-hover: var(--wh-secondary-300);--wh-bg-front-hover-strong: var(--wh-secondary-200);--wh-border-front: hsl(227, 20%, 25%);--wh-border-front-strong: hsl(227, 20%, 35%);--wh-text-stronger: hsla(0, 0%, 100%, 0.95);--wh-text-strongest: hsla(0, 0%, 100%, 1);--wh-text-strong: rgba(255, 255, 255, 0.9);--wh-text: rgba(255, 255, 255, 0.85);--wh-text-hover: var(--wh-text-strong);--wh-text-light: rgba(255, 255, 255, 0.73);--wh-text-lighter: rgba(255, 255, 255, 0.63);--wh-text-lightest: rgba(255, 255, 255, 0.5);--wh-border-color: hsla(0, 0%, 100%, 0.15);--wh-border-color-strong: hsla(0, 0%, 100%, 0.25);--wh-note-editor-bg-color: hsl(221, 27%, 20%);--wh-note-editor-bg-color-preview: hsl(221, 27%, 18%);--wh-bg-tags: var(--wh-secondary-300);--wh-bg-tags-hover: var(--wh-secondary-200);--wh-syntax-bg-color: rgba(255, 255, 255, 0.05);--wh-fallback-img-color: var(--wh-secondary-600);--wh-bg-disabled: hsl(220, 22%, 18%);--wh-bg-notification-unread: hsla(161, 100%, 20%, 0.15);--wh-bg-notification-unread-hover: hsla(161, 100%, 20%, 0.05);--wh-subtle-gray: rgb(255, 255, 255, 0.1);--wh-shadow: inset 0 0 0.5px 1px hsla(0, 0%, 100%, 0.1),
      /* 2. shadow ring 👇 */ 0 0 0 1px hsla(230, 13%, 9%, 0.075),
      /* 3. multiple soft shadows 👇 */ 0 0.3px 0.4px hsla(230, 13%, 9%, 0.02),
      0 0.9px 1.5px hsla(230, 13%, 9%, 0.045),
      0 3.5px 6px hsla(230, 13%, 9%, 0.09);--wh-shadow-primary: var(--wh-primary-500) 0px 0px 0px 1px inset,
      var(--wh-primary-500) 0px 0px 1px; }</style><script src="./Codédex _ Generate a Blog with OpenAI_files/plausible.js.download" defer="true" data-domain="codedex.io" data-nscript="afterInteractive"></script><next-route-announcer><p aria-live="assertive" id="__next-route-announcer__" role="alert" style="border: 0px; clip: rect(0px, 0px, 0px, 0px); height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; top: 0px; width: 1px; white-space: nowrap; overflow-wrap: normal;"></p></next-route-announcer><div id="webhighlights-notifications"></div><style id="web-highlights-global-styles">
  webhighlights-sidebar {
    --webhighlights-font-size: 13.5px;
  }

  body.web-highlights-animate {
    transition: all 300ms linear;
    transition-property: margin-left, margin-right;
  }

  body.web-highlights-open {
    margin-left: 400px !important;
  }

  web-highlight.webhighlights-highlight {
    border-radius: 2px;
    background-color: #92ffaa;
    cursor: pointer;
    visibility: visible !important;
  }

  web-highlight.webhighlights-highlight.webhighlight-with-tags,
  web-highlight.webhighlights-highlight.webhighlight-with-notes {
    border-bottom: 2.8px solid gray;
    border-radius: 0px;
  }

  web-highlight > *:not(webhighlights-popup-toolbox) {
    background-color: #92ffaa;
  }

  webhighlights-popup-toolbox.contains-highlight {
    transform: translate(-63px, -10px);
    position: fixed;
  }
</style><webhighlights-popup-toolbox><template shadowrootmode="open"><!---->
      <!--?lit$750507845$-->
    </template></webhighlights-popup-toolbox><webhighlights-marker><template shadowrootmode="open"><!---->
      <!--?lit$750507845$-->
            <webhighlights-popup-toolbox data-testid="webhighlights-marker-POPUP_TOOLBOX"><template shadowrootmode="open"><!---->
      <!--?lit$750507845$-->
    </template></webhighlights-popup-toolbox>
          
    </template></webhighlights-marker><script src="./Codédex _ Generate a Blog with OpenAI_files/c7773329-fa54bb63dd92cb08.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/builds-54598d1833b3f0a9.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/d7eeaac4-345ec750cd25c88a.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1a48c3c1-23dfc3ea935e511d.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/7f0c75c1-b1f616c95e740897.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/d64684d8-a4c1c1cfc924dd52.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1e7c12d4-0d18fbb6ccb999fe.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/78e521c3-62c26b4faa24efe6.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/de71a805-7c3eede966dba0ce.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9755-bff09260aef52f12.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/2238-de67480ff11cdf2f.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/8494-580b351760cfb8cc.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/5818-371a274055635211.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/195-7021e15a6bcaa3ec.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/3623-b6972b8b2444212c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/463-c020b1f6fcf82b36.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/5858-217749e23530c83c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/514-ecfa057b0332c3fa.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9227-fe997dff71fb3a7a.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9840-7df7daf4b3c34697.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/community-3e34973f6b297308.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1bfc9850-71d91d5d4c4301f0.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1582-8563d1ad7cedcde7.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/5012-a830fa1dad89f297.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/[username]-619ba8ac78469e98.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/1808-be540380790b01c5.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/2042-0fea4c4d00ff07c2.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/python-f34bca7ab3dcab3b.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/7939-cccc9c103cccaf4f.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/index-f608ed53b785bc8e.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/home-634ddd182568da57.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/projects-aa1ce341089ea4d7.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/about-b5a1a2bf867004d8.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/7536-4bba4712c2e8106f.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/9028-3c3b16f34e5a0cf4.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/blog-97568d8bc061a9a9.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/8764-6825f04985bb7b7c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/7066-2f965d9ee63bca07.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/6960-9ac039b89504e9a6.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/967-da4a083246e26285.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/5966-030f98d6e6e29bab.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/pricing-c60a82a8acdf2b8c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/challenges-957f14482b9c008c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/6670-899a6d8dcf09244d.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/2939-7d559b10db873f7e.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/30-nites-of-code-1c52a1088a9477ad.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/courses-992514bb12435da1.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/intermediate-python-745e157bba3bb879.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/numpy-4c748d0e13d214b7.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/sql-ed8646296cb4bda5.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/html-60190679aa30ac93.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/css-217b7281471acfbe.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/javascript-7261cf923525ef6d.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/intermediate-javascript-bffb0e8848f015ea.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/react-f32496530a57d7b0.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/command-line-08a894d029c2d9a5.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/git-github-5362064c420d294e.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/p5js-1aad133b1167a4b3.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/cpp-1803950b1b5f30eb.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/java-346a89f9d8031fef.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/terms-55d86140e1fe697c.js.download"></script><script src="./Codédex _ Generate a Blog with OpenAI_files/privacy-5838503a47853cdd.js.download"></script><iframe name="__privateStripeMetricsController4840" frameborder="0" allowtransparency="true" scrolling="no" role="presentation" allow="payment *" src="./Codédex _ Generate a Blog with OpenAI_files/m-outer-3437aaddcdf6922d623e172c2d6f9278.html" aria-hidden="true" tabindex="-1" style="border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;"></iframe><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom"></iframe><div class="intercom-lightweight-app"><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #FFD720;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 40px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 20px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: #D9F3C3

    
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
    
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div></body><webhighlights-sidebar alignment="left" sidebar-width="400"><template shadowrootmode="open"><!---->
      <!--?lit$750507845$-->
            <main-component part="main-component" data-testid="webhighlights-sidebar-MAIN_COMPONENT" style="left: 0px; right: unset;"><template shadowrootmode="open"><!---->
      <webhighlights-popover data-testid="main-component-POPOVER"><template shadowrootmode="open"><!----><!--?--></template>
        <!--?lit$750507845$--><!--?-->
      </webhighlights-popover>

      <!-- Button to toggle side-bar. It hides when animation is active -->
      <!--?lit$750507845$--><!--?-->
      <!--?lit$750507845$-->
    </template></main-component>
          
      <!--?lit$750507845$--><!--?-->
    </template></webhighlights-sidebar></html>